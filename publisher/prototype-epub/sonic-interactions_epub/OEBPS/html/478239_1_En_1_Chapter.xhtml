<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops"><head><title>Sonic Interactions in Virtual Environments: The Egocentric Audio Perspective of the Digital Twin</title><meta content="text/html; charset=utf-8" http-equiv="content-type"/><link href="../css/springer_epub.css" rel="styleSheet" type="text/css"/></head><body><div epub:type="chapter" role="doc-chapter"><div class="ChapterContextInformation"><div class="ContextInformation" id="Chap1"><div class="ChapterCopyright">© The Author(s) 2023</div><span class="ContextInformationAuthorEditorNames">M. Geronazzo, S. Serafin<span class="CollaboratorDesignation"> (eds.)</span></span><span class="ContextInformationBookTitles"><span class="BookTitle">Sonic Interactions in Virtual Environments</span></span><span class="ContextInformationSeries"><span class="SeriesTitle" lang="en">Human–Computer Interaction Series</span></span><span class="ChapterDOI"><a href="https://doi.org/10.1007/978-3-031-04021-4_1">https://doi.org/10.1007/978-3-031-04021-4_1</a></span></div></div><!--Begin Abstract--><div class="MainTitleSection"><h1 class="ChapterTitle" lang="en">1. Sonic Interactions in Virtual Environments: The Egocentric Audio Perspective of the Digital Twin</h1></div><div class="AuthorGroup"><div class="AuthorNames"><span class="Author"><span class="AuthorName">Michele Geronazzo</span><sup><a href="#Aff34">1</a>, <a href="#Aff35">2</a>, <a href="#Aff36">3</a> <a aria-label="Contact information for this author" href="#ContactOfAuthor1"><span class="ContactIcon"> </span></a></sup> and </span><span class="Author"><span class="AuthorName">Stefania Serafin</span><sup><a href="#Aff37">4</a> <a aria-label="Contact information for this author" href="#ContactOfAuthor2"><span class="ContactIcon"> </span></a></sup></span></div><div class="Affiliations"><div class="Affiliation" id="Aff34"><span class="AffiliationNumber">(1)</span><div class="AffiliationText">Department of Engineering and Management, University of Padova, Padova, Italy</div></div><div class="Affiliation" id="Aff35"><span class="AffiliationNumber">(2)</span><div class="AffiliationText">Dyson School of Design Engineering, Imperial College London, London, UK</div></div><div class="Affiliation" id="Aff36"><span class="AffiliationNumber">(3)</span><div class="AffiliationText">Department of Humanities and Cultural Heritage, University of Udine, Udine, Italy</div></div><div class="Affiliation" id="Aff37"><span class="AffiliationNumber">(4)</span><div class="AffiliationText">Department of Architecture, Design, and Media Technology, Aalborg University Copenhagen, Copenhagen, Denmark</div></div><div class="ClearBoth"> </div></div><div class="Contacts"><div class="Contact" id="ContactOfAuthor1"><div class="ContactIcon"> </div><div class="ContactAuthorLine"><span class="AuthorName">Michele Geronazzo</span> (Corresponding author)</div><div class="ContactAdditionalLine"><span class="ContactType">Email: </span><a href="mailto:michele.geronazzo@unipd.it">michele.geronazzo@unipd.it</a></div></div><div class="Contact" id="ContactOfAuthor2"><div class="ContactIcon"> </div><div class="ContactAuthorLine"><span class="AuthorName">Stefania Serafin</span></div><div class="ContactAdditionalLine"><span class="ContactType">Email: </span><a href="mailto:sts@create.aau.dk">sts@create.aau.dk</a></div></div></div></div><section class="Abstract" id="Abs1" lang="en" role="doc-abstract"><h2 class="Heading">Abstract</h2><p class="Para" id="Par1">The relationships between the listener, physical world, and virtual environment (VE) should not only inspire the design of natural multimodal interfaces but should be discovered to make sense of the mediating action of VR technologies. This chapter aims to transform an archipelago of studies related to sonic interactions in virtual environments (SIVE) into a research field equipped with a first theoretical framework with an inclusive vision of the challenges to come: the egocentric perspective of the auditory digital twin. In a VE with immersive audio technologies implemented, the role of VR simulations must be enacted by a participatory exploration of sense-making in a network of human and non-human agents, called actors. The guardian of such locus of agency is the auditory digital twin that fosters intra-actions between humans and technology, dynamically and fluidly redefining all those configurations that are crucial for an immersive and coherent experience. The idea of entanglement theory is here mainly declined in an egocentric spatial perspective related to emerging knowledge of the listener’s perceptual capabilities. This is an actively transformative relation with the digital twin potentials to create movement, transparency, and provocative activities in VEs. The chapter contains an original theoretical perspective complemented by several bibliographical references and links to the other book chapters that have contributed significantly to the proposal presented here.</p></section><!--End Abstract--><div class="Fulltext"><section class="Section1 RenderAsSection1" id="Sec1"><h2 class="Heading"><span class="HeadingNumber">1.1 </span>Introduction</h2><p class="Para" id="Par2">Our daily auditory experience is characterized by immersion from the very beginning of our life inside the womb, actively listening to sounds surrounding us from different positions in space. Auditory information takes the form of a binaural continuous stream of messages to the left and right ears, conveying a compact representation of the omnidirectional source of learning for our existence [<span class="CitationRef"><a epub:type="biblioref" href="#CR19" role="doc-biblioref">19</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR48" role="doc-biblioref">48</a></span>]. Both temporal and spatial activity of sounds of interest (e.g., dialogues, alarms, etc.) allow us to localize and encode the contextual information and intentions of our social interaction [<span class="CitationRef"><a epub:type="biblioref" href="#CR1" role="doc-biblioref">1</a></span>].</p><p class="Para" id="Par3">The hypothesis that our daily listening experience of sounding objects with certain physical characteristics dynamically shapes the acoustic features for which we ascribe meaning to our auditory world is supported by one of the key concepts in Husserl’s phenomenology <em class="EmphasisTypeItalic ">“Meaning-bestowal”</em> (“Sinngebung” in German [<span class="CitationRef"><a epub:type="biblioref" href="#CR73" role="doc-biblioref">73</a></span>]) and by studies in ecological acoustics such as [<span class="CitationRef"><a epub:type="biblioref" href="#CR48" role="doc-biblioref">48</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR54" role="doc-biblioref">54</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR96" role="doc-biblioref">96</a></span>]. In particular, the idea of acoustic invariant as a complex pattern of change for a real-world sound interaction is strongly related to human perceptual learning and a socio-cultural mediation dictated by the real world. For some surveys of classical studies on the topic of ecological acoustics refer to [<span class="CitationRef"><a epub:type="biblioref" href="#CR112" role="doc-biblioref">112</a></span>].</p><p class="Para" id="Par4">From this perspective, acoustic invariants are learned on an individual basis through experiential learning. Hence, there is the need to trace their development over multiple experiences and to formalize a common ground for a dynamic expansion of individual knowledge. Any emerging understanding should be transferred to a technological system able to provide an immersive and interactive simulation of a sonic virtual environment (VE). Such a process must be adaptive and dynamic to ensure a level of coupling between user and technology in such a way that the active listening experience is considered authentic.</p><p class="Para" id="Par5">Immersive virtual reality (here we generically referred to as VR) technologies allow immense flexibility and increasing possibilities for the creation of VEs with relationships or interactions that might be ontologically relevant even if radically different from the physical world. This can be evident by referring to the distinction between naturalistic and magical interactions, where the latter can be considered observable system configurations in the domain of artificial illusions, incredibly expanding the spectrum of possible digital experiences [<span class="CitationRef"><a epub:type="biblioref" href="#CR13" role="doc-biblioref">13</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR127" role="doc-biblioref">127</a></span>].</p><p class="Para" id="Par6">One of the main research topics in the VR and multimedia communities is rendering. For decades, computer-aided design applications have favored—in the first place—the development of computer graphics algorithms. Some of these approaches, e.g., geometric ray-tracing methods, have been adapted to model sound propagation in complex VEs (see Chap. <span class="ExternalRef"><a href="478239_1_En_3_Chapter.xhtml"><span class="RefSource">3</span></a></span> for more details). However, there has been a clear tendency to prioritize resources and research on the visual side of virtual reality, confining auditory information to a secondary and ancillary role [<span class="CitationRef"><a epub:type="biblioref" href="#CR158" role="doc-biblioref">158</a></span>]. Although sound is an essential component of the grammar of digital immersion, relatively little compared to the visual side of things has been done to investigate the role of auditory space and environments. Nowadays, there is increasing consensus toward the essential contribution of spatial sound, also in (VR) simulations [<span class="CitationRef"><a epub:type="biblioref" href="#CR9" role="doc-biblioref">9</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR102" role="doc-biblioref">102</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR145" role="doc-biblioref">145</a></span>]. Technologies for <strong class="EmphasisTypeBold ">spatial audio rendering</strong> are now able to convey perceptually plausible simulations with stimuli that are reconstructed from real-life recordings [<span class="CitationRef"><a epub:type="biblioref" href="#CR18" role="doc-biblioref">18</a></span>] or historical archives, as for the Cathédrale Notre-Dame de Paris before and after the 2019 fire [<span class="CitationRef"><a epub:type="biblioref" href="#CR79" role="doc-biblioref">79</a></span>], getting closer to a virtual version indistinguishable from the natural reality [<span class="CitationRef"><a epub:type="biblioref" href="#CR77" role="doc-biblioref">77</a></span>]. This is made possible by a high level of personalization in modeling user morphology and acoustic transformations caused by the human body interacting with the sound field generated in room acoustic computer simulations [<span class="CitationRef"><a epub:type="biblioref" href="#CR17" role="doc-biblioref">17</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR78" role="doc-biblioref">78</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR114" role="doc-biblioref">114</a></span>].</p><p class="Para" id="Par7">Nowadays, the boundary between technology and humans has increasingly blurred thanks to recent developments in research areas such as virtual and augmented reality, artificial intelligence, cyber-physical systems, and neuro-implants. It is not possible to easily distinguish where the human ends and the technology begins. For this reason, we embrace the idea of [<span class="CitationRef"><a epub:type="biblioref" href="#CR10" role="doc-biblioref">10</a></span>] who sees technology as a lens for the understanding of what it means to be human in a changing world. We can therefore consider the <em class="EmphasisTypeItalic ">phenomenal transparency</em> [<span class="CitationRef"><a epub:type="biblioref" href="#CR94" role="doc-biblioref">94</a></span>] where technology takes on the role of a transparent mediator for self-knowledge. According to Loomis [<span class="CitationRef"><a epub:type="biblioref" href="#CR88" role="doc-biblioref">88</a></span>], the <strong class="EmphasisTypeBold ">phenomenology of presence</strong> between physical and virtual environments places the internal listener representation created by the spatial senses and the brain on the same level. Human-technology-reality relations are thus created by enactivity that allows a fluid and dynamic entanglement of all the involved actors.</p><p class="Para" id="Par8">In this chapter, we initially adopt Slater’s definition of <span id="ITerm1">presence</span> for an immersive VR system [<span class="CitationRef"><a epub:type="biblioref" href="#CR135" role="doc-biblioref">135</a></span>] embracing the recent revision by Skarbez [<span class="CitationRef"><a epub:type="biblioref" href="#CR134" role="doc-biblioref">134</a></span>]. The concepts of plausibility illusion and place illusion are central to capturing the subjective internal states. While the plausibility illusion determines the overall credibility of a VE in terms of subjective expectations, the place illusion establishes the quality of having sensations of being in a real place. They are both fundamental in providing credibility to a digital simulation based on individual experience and expectations concerning an internal frame of reference for scenes, environments, and events.<sup><a epub:type="noteref" href="#Fn1" id="Fn1_source" role="doc-noteref">1</a></sup>
</p><p class="Para" id="Par10">We propose a theoretical framework for the new field of study, namely Sonic Interactions in Virtual Environments (SIVE). We suggest from now on a unified reading of this chapter with references and integrations from all chapters of the corresponding book [<span class="CitationRef"><a epub:type="biblioref" href="#CR49" role="doc-biblioref">49</a></span>]. Each chapter provides state-of-the-art challenges and case studies for specific SIVE-related topics curated by internationally renowned scientists and their collaborators. The provided point of view focuses on the relations between real auditory experience and technologically mediated experiences in immersive VR. The first is characterized by individuality to confer immersiveness within a physical world. It is important to emphasize the omnidirectionally of auditory information that allows the listener to collect both the whole and the parts at 360<span class="InlineEquation" id="IEq1"><img alt="$$^{\circ }$$" src="../images/478239_1_En_1_Chapter/478239_1_En_1_Chapter_TeX_IEq1.png" style="width:0.57em"/></span>. The individualized auditory signals are the result of the acoustic transformations made by the head, ear, and torso of the listener that act as a spatial fingerprint for a complex spatio-temporal signal. Familiarity, and therefore previous experience with sounds, shape spatial localization capabilities with high intersubjectivity. Finally, studies on neural plasticity of the human brain confirm continuous adaptability of listening with impaired physiological functions, e.g., a hearing loss, and with electrical stimulation, e.g., via cochlear implants [<span class="CitationRef"><a epub:type="biblioref" href="#CR82" role="doc-biblioref">82</a></span>].</p><p class="Para" id="Par11">The <strong class="EmphasisTypeBold ">mediated VR experience</strong> is often characterized by the user’s digital counterpart called avatar. It allows the creation of an embodied and situated experience in digital VEs. The scientific literature supports the idea that the manipulation of VR simulations can induce changes at the cognitive level [<span class="CitationRef"><a epub:type="biblioref" href="#CR124" role="doc-biblioref">124</a></span>], such as in educational [<span class="CitationRef"><a epub:type="biblioref" href="#CR34" role="doc-biblioref">34</a></span>] and therapeutic [<span class="CitationRef"><a epub:type="biblioref" href="#CR106" role="doc-biblioref">106</a></span>] positive effects. The ability of VR technologies to mediate within the immersive environment in embodied and situated relations gives immersive technologies the opportunities to change one’s self [<span class="CitationRef"><a epub:type="biblioref" href="#CR151" role="doc-biblioref">151</a></span>].</p><p class="Para" id="Par12">For these reasons, we believe it is time to coin, at the terminological level, a new perspective that relates the two listening experiences (i.e., real and virtual), called <strong class="EmphasisTypeBold ">egocentric audio perspective</strong>. In particular, we refer to the term audio to identify an auditory sensory component, implicitly recalling those technologies capable of immersive and interactive rendering. The term egocentric refers to the perceptual reference system for the acquisition of multisensory information in immersive VR technologies as well as the sense of subjectivity and perceptual/cognitive individuality that shape the self, identity, or consciousness. In accordance with Husserl’s phenomenology, the human body can be philosophically defined as a “Leib”, a living body, and a “Nullpunkt”, a zero-point of reference and orientation [<span class="CitationRef"><a epub:type="biblioref" href="#CR73" role="doc-biblioref">73</a></span>].</p><p class="Para" id="Par13">This perspective aims to extend the discipline of <span id="ITerm2">Sonic Interaction Design</span> [<span class="CitationRef"><a epub:type="biblioref" href="#CR44" role="doc-biblioref">44</a></span>] by taking into account not only the importance of sound as the main channel conveying information, meaning, aesthetic, and emotional qualities, but rather an egocentric perspective of entanglement between the perceiving subject and the computer simulating the perceived environment. In the first instance, this can be described by processes of personalization, adaptation, and mutual relations to maintain the immersive illusion. However in this chapter, we will try to argue that it is much more than that. We hope that our vision will guide the development of new immersive audio technologies and conscious use of sound design within VEs.</p><p class="Para" id="Par14">The starting point of this theoretical framework is an ecologically egocentric perspective. The foundational phenomenological assumption considers a self-propelled entity with agency and intentionality [<span class="CitationRef"><a epub:type="biblioref" href="#CR47" role="doc-biblioref">47</a></span>]. It can interact with the VE being aware of its activities in a three-dimensional space. The active immersion in a simulated acoustic field provides it meaningful experiences through sound.</p><p class="Para" id="Par15">Therefore, it is important to introduce a terminological characterization of what is the <strong class="EmphasisTypeBold ">listener</strong>, not a user in this context, as a human being with prior experience and subjective auditory perception. A closely related entity is the <strong class="EmphasisTypeBold ">auditory digital twin</strong>, which differs from the most common <span id="ITerm3">avatar</span>. The idea of an avatar within a digital simulation co-located with objects, places, and other avatars [<span class="CitationRef"><a epub:type="biblioref" href="#CR126" role="doc-biblioref">126</a></span>] requires a user taking control of any form of virtual bodies which might be noticeably different from that of the listener’s physical body. On the other hand, the digital twin cannot disregard an egocentric perspective of the listener for whom it is created. This means that the relations with the VEs should consider personalization techniques on the virtual body closely linked to the listener’s biological body. This mediation is essential for the interactions between the listener and all the diegetic sounds, whether they are produced by the avatar’s gestures or by sound sources in the VE.</p><p class="Para" id="Par16">In such a context, immersiveness is a dynamic relationship between physical and meaningful actions by the listener in the VE. Specifically, having performed bodily practices such as walking, sitting, talking, grasping, etc. provide meaning to virtual places, objects, and avatars [<span class="CitationRef"><a epub:type="biblioref" href="#CR59" role="doc-biblioref">59</a></span>]. Accordingly, the sense of embodiment can be considered a subjective internal feeling which is an expression of the relationship between one’s self and such VE. In this regard, Kilteni et al. [<span class="CitationRef"><a epub:type="biblioref" href="#CR80" role="doc-biblioref">80</a></span>] identified the sense of embodiment for an artificial body (i.e., avatar) in the mediation between the avatar’s properties and their processing by the user’s biological properties.</p><p class="Para" id="Par17">We now introduce the technological mediation in the form of an auditory digital twin which is a guardian and facilitator of (i) the sense of self-location, (ii) plausibility, (iii) body ownership, and (iv) agency for the listener. In the first instance, a performative view might make us see realities as “ a doing”, enacting practical actions [<span class="CitationRef"><a epub:type="biblioref" href="#CR6" role="doc-biblioref">6</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR104" role="doc-biblioref">104</a></span>]. Similarly, the listener and the avatar cannot be considered fixed and independent interacting entities, but constituent parts of emergent, multiple and dynamic phenomena resulting from entangled social, cognitive, and perceptual elements. This <strong class="EmphasisTypeBold ">intra-systemic action</strong> of entangled elements dynamically constructs identities and properties of the immersive listening experience. The illusory permanence of auditory immersion lies in the boundaries between situationally entangled elements in fluid and dynamic situations. They can be seen as confrontations occurring exactly in the auditory digital twin that facilitates the phenomenon. The auditory digital twin is the meeting and shared place between the listener and a virtual body identity, communicating in a non-discursive (performative) way according to the quality level of the digital simulation.</p><p class="Para" id="Par18">In an immersive VE, the listeners cannot exist without their auditory digital twin and vice versa. Through the digital twin characterization, the acoustic signals generated by the VE are filtered exclusively for the listeners, according to their ability to extract meaningful information. It is worthwhile to mention the <strong class="EmphasisTypeBold ">participatory nature</strong> of such entanglement process between listener and digital twin, as a joint exploration of the listener’s attentional process in selecting meaningful information, e.g., the cocktails party effect [<span class="CitationRef"><a epub:type="biblioref" href="#CR20" role="doc-biblioref">20</a></span>]. We might speculate by considering a simulation that interacts within the digital twin to provide the best pattern or to discover it in order to attract the listener’s attention. The decision-making process will then be the result of intra-action in and of the auditory digital twin.</p><p class="Para" id="Par19">This chapter has three main sections. Section <span class="InternalRef"><a href="#Sec2">1.2</a></span> gathers the different souls that characterize the research and artistic works in SIVE. Section <span class="InternalRef"><a href="#Sec3">1.3</a></span> holds a central position by defining the constitutive elements of our proposed egocentric audio perspective in SIVE: spatial centrality and entanglement between human and computer in the digital twin. In Sect. <span class="InternalRef"><a href="#Sec10">1.4</a></span>, we attempt incorporating this theoretical framework by adapting Milgram and Kishino’s well-known taxonomy for VR [<span class="CitationRef"><a epub:type="biblioref" href="#CR95" role="doc-biblioref">95</a></span>], with an audio-first perspective. Finally, Sect. <span class="InternalRef"><a href="#Sec14">1.5</a></span> concludes this chapter by encouraging a new starting point for SIVE. We suggest an inclusive approach to the next paradigm shift in the field of human-computer interaction (HCI) discipline.</p></section><section class="Section1 RenderAsSection1" id="Sec2"><h2 class="Heading"><span class="HeadingNumber">1.2 </span>SIVE: From an Archipelago to a Research Field</h2><div class="Para" id="Par20">This chapter aims to provide an interpretation to an archipelago of researches from different communities such as<div class="UnorderedList"><ul class="UnorderedListMarkBullet"><li><p class="Para" id="Par21"><span id="ITerm4">Sound and Music Computing</span> (SMC) network, a point of convergence for different research disciplines mainly related to digital processing of musical information.<sup><a epub:type="noteref" href="#Fn2" id="Fn2_source" role="doc-noteref">2</a></sup>
</p></li><li><p class="Para" id="Par23">International Community for Auditory Display (ICAD), a point of convergence for different areas of research with digital processing of non-musical audio information and the idea of sonification in common.<sup><a epub:type="noteref" href="#Fn3" id="Fn3_source" role="doc-noteref">3</a></sup>
</p></li><li><p class="Para" id="Par25">The Audio Engineering Society (AES), the main community for institutions and companies devoted to the world of audio technologies.<sup><a epub:type="noteref" href="#Fn4" id="Fn4_source" role="doc-noteref">4</a></sup>
</p></li><li><p class="Para" id="Par27">The research community gathered by the International Conference on <span id="ITerm5">New Interfaces for Musical Expression</span> (NIME), devoted to interactions with new interfaces with the aim at facilitating the human creative process.<sup><a epub:type="noteref" href="#Fn5" id="Fn5_source" role="doc-noteref">5</a></sup>
</p></li><li><p class="Para" id="Par29">The Digital Audio Effects community (DAFX) aiming at designing technological-based simulations of sonic phenomena.<sup><a epub:type="noteref" href="#Fn6" id="Fn6_source" role="doc-noteref">6</a></sup>
</p></li></ul></div>
</div><p class="Para" id="Par31">We employ here the metaphor of an <span id="ITerm6">archipelago</span> because it well describes a context in which all these communities address aspects of VR according to their specificities, influencing each other. After all, they share the same “waters”. They are relatively close to each other but feeling distant from a VR community at the same time, like the islands of an archipelago in the open sea. Thus, we affirm the need to unify the fragmentary and specificity of those studies and to fill the gap with their visual counterpart’s aiming at developing immersive VR environments for sound and music. To achieve this goal, the editors have pursued the following spontaneous path that is characterized by three main steps.</p><div class="Para" id="Par32"><div class="OrderedList"><ol><li class="ListItem"><div class="ItemNumber">1.</div><div class="ItemContent"><p class="Para" id="Par33">The first review article related to SIVE topics, dated back to 2018 [<span class="CitationRef"><a epub:type="biblioref" href="#CR128" role="doc-biblioref">128</a></span>], focused on the technological components characterizing an immersive potential for interactive sound environments. In that work, the editors and their collaborators produced a first compact survey including sound synthesis, propagation, rendering, and reproduction with a focus on the ongoing development of headphone technologies.</p></div><div class="ClearBoth"> </div></li><li class="ListItem"><div class="ItemNumber">2.</div><div class="ItemContent"><p class="Para" id="Par34">Two years later, we published a second review paper together with all the organizers of the past five editions of the IEEE Virtual Reality’s SIVE workshop [<span class="CitationRef"><a epub:type="biblioref" href="#CR129" role="doc-biblioref">129</a></span>]. In this paper, we analyzed the contributions presented at the various editions highlighting the emerging aspects of interaction design, presence, and evaluation. An inductive approach was adopted, supported by a posteriori analysis of the characterizing categories of SIVE so far.</p></div><div class="ClearBoth"> </div></li><li class="ListItem"><div class="ItemNumber">3.</div><div class="ItemContent"><p class="Para" id="Par35">Finally, this book and, in particular, this chapter want to raise the bar further with an organic and structured narrative of an emerging discipline. We aim to provide a theoretical framework for interpreting and accompanying the evolution of SIVE, focusing on the close relationship between physically real and virtual auditory experiences described in terms of immersive, coherent, and entangled features.</p></div><div class="ClearBoth"> </div></li></ol></div>
</div><div class="Para" id="Par36">This chapter is the result of the convergence of two complementary analytical strategies: (i) a <em class="EmphasisTypeItalic ">top-down </em>approach describing the structure given by the editors to the book originated from the studies experienced by the editors themselves, and (ii) a <em class="EmphasisTypeItalic ">bottom-up </em>approach drawing on the knowledgeable insights of the contributing authors of this book on several specialist and interdisciplinary aspects. Consequently, we will constantly refer to these chapters in an attempt to provide a unified and long-term vision for <span id="ITerm7">SIVE</span>.<figure class="Figure" id="Fig1"><div class="MediaObject" id="MO1"><img alt="" src="../images/478239_1_En_1_Chapter/478239_1_En_1_Fig1_HTML.png" style="width:28.9em"/></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 1.1</span><p class="SimplePara">The SIVE inverse pyramid. Arrows indicate high-level relational hierarchies</p></div></figcaption></figure>
</div><div class="Para" id="Par37">Our proposal for the definition of a new research field starts from a simple layer structure without claiming to be exhaustive. The graphical representation in Fig. <span class="InternalRef"><a href="#Fig1">1.1</a></span> is capable of giving an overview and a rough inter-relation of the multidisciplinarity involved in SIVE. We suggest a hierarchical structure for the various disciplines in the form of an inverted pyramid representation. SIVE research can be conceptually organized in three levels: <div class="OrderedList"><ol><li class="ListItem"><div class="ItemNumber">i</div><div class="ItemContent"><p class="Para" id="Par38"><strong class="EmphasisTypeBold ">Immersive audio</strong> concerns the computational aspects of the acoustical-space properties of technologies. It involves the study of acoustic aspects, psychoacoustic, computational, and algorithmic representation of the auditory information, and the development of enabling audio technologies;</p></div><div class="ClearBoth"> </div></li><li class="ListItem"><div class="ItemNumber">ii</div><div class="ItemContent"><p class="Para" id="Par39"><strong class="EmphasisTypeBold ">Sonic interaction</strong> refers to human-computer interplay through auditory feedback in 3D environments. It comprises the study of vibroacoustic information and its interaction with the user to provide abstract meanings, specific indicators of the state for a process or activity in interactive contexts;</p></div><div class="ClearBoth"> </div></li><li class="ListItem"><div class="ItemNumber">iii</div><div class="ItemContent"><p class="Para" id="Par40">The <strong class="EmphasisTypeBold ">integration</strong> of immersive audio in multimodal VR/AR systems impacts different application domains. This third and final level collects all the studies regarding the integration of virtual environments in different application domains such as rehabilitation, health, psychology, music, to name but a few.</p></div><div class="ClearBoth"> </div></li></ol></div>
</div><div class="Para" id="Par41">The immersive audio layer is a strongly characterizing element of SIVE. For such a reason, it is placed as the tip of the inverse pyramid, where all SIVE development opportunities originate. In other words, SIVE cannot exist without sound spatialization technologies, and the research built upon them is intrinsically conditioned by the level of technological development (for more arguments on this issue see Sect. <span class="InternalRef"><a href="#Sec8">1.3.2</a></span>).<figure class="Figure" id="Fig2"><div class="MediaObject" id="MO2"><img alt="" src="../images/478239_1_En_1_Chapter/478239_1_En_1_Fig2_HTML.png" style="width:24.5em"/></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 1.2</span><p class="SimplePara">High-level acoustic components for immersive audio with a focus on spatial room acoustics and headphone reproduction</p></div></figcaption></figure>
</div><p class="Para" id="Par42">In particular, spatial audio rendering through headphones involves the computation of binaural room impulse <span id="ITerm8">responses</span> (BRIRs) to capture/render sound sources in space (see Fig. <span class="InternalRef"><a href="#Fig2">1.2</a></span>). BRIRs can be separated into two distinct components: the room impulse response (RIR)<span id="ITerm9"/>, which defines room acoustic properties, and the head-related impulse response (HRIR) or head-related transfer function (HRTF, i.e., the HRIR in the frequency domain)<span id="ITerm10"/>, which acoustically describes the individual contributions of the listener’s head, pinna, torso, and shoulders. The former describes the acoustic space and environment, while the latter prepares this information into perceptually relevant spatial acoustic cues for the auditory system, taking advantage of the flexibility of <strong class="EmphasisTypeBold ">immersive binaural synthesis through headphones</strong> and state-of-the-art consumer head-mounted displays (HMDs) for VR. The perceptually coherent auralization with lifelike acoustic phenomena, taking into account the effects of near-field acoustics and listener specificity in user and headphones acoustics, is a key technological matter here [<span class="CitationRef"><a epub:type="biblioref" href="#CR11" role="doc-biblioref">11</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR21" role="doc-biblioref">21</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR68" role="doc-biblioref">68</a></span>].</p><div class="Para" id="Par43">The visual component of spatial immersion is so evident that it may seem that the sensation of immersion is exclusively dependent on it, but the aural aspect has as much or even more relevance. We can simulate an interactive listening experience within VR using standard components such as headsets, digital signal processors (DSPs), inertial sensors, and handheld controllers. Immersive audio technologies have the potential to revolutionize the way we interact socially within VR environments and applications. Users can navigate immersive content employing head motions and translations in 3D space with 6 degrees of freedom (DoF). When immersive auditory feedback is provided in an ecologically valid interactive multisensory experience, a perceptually plausible scheme for developing sonic interactions is practically convenient [<span class="CitationRef"><a epub:type="biblioref" href="#CR128" role="doc-biblioref">128</a></span>], yet still efficient in computational power, memory, and latency (refer to Chap. <span class="ExternalRef"><a href="478239_1_En_3_Chapter.xhtml"><span class="RefSource">3</span></a></span> for further details). The trade-off between accuracy and plausibility is complex and finding algorithms that can parameterize sound rendering remains challenging [<span class="CitationRef"><a epub:type="biblioref" href="#CR62" role="doc-biblioref">62</a></span>]. The creation of an immersive sonic experience requires<div class="UnorderedList"><ul class="UnorderedListMarkBullet"><li><p class="Para" id="Par44"><em class="EmphasisTypeItalic ">Action sounds</em>: sound produced by the listener that changes with movement,</p></li><li><p class="Para" id="Par45"><em class="EmphasisTypeItalic ">Environmental sounds</em>: sounds produced by objects in the environment, referred to as soundscapes,</p></li><li><p class="Para" id="Par46"><em class="EmphasisTypeItalic ">Sound propagation</em>: acoustic simulation of the space, i.e., room acoustics,</p></li><li><p class="Para" id="Par47"><em class="EmphasisTypeItalic ">Binaural rendering</em>: user-specific acoustics that provides for auditory localization.</p></li></ul></div>
</div><p class="Para" id="Par48">These are the virtual acoustics and auralization key elements [<span class="CitationRef"><a epub:type="biblioref" href="#CR153" role="doc-biblioref">153</a></span>] at the basis of auditory feedback design that draws on user attention and enhances the sensation of place and space in virtual reality scenarios [<span class="CitationRef"><a epub:type="biblioref" href="#CR102" role="doc-biblioref">102</a></span>].</p><p class="Para" id="Par49">The two upper layers of the SIVE inverse pyramid, i.e., sonic interactions and multimodal experiences, are not clearly distinguishable and we propose the following interpretation: we differentiate the interaction from the experience layer when we intend to extrapolate design rules for the sonic component with a different meaning for the designer, system, users, etc. . In both cases, embodiment and proprioception are essential, naturally supporting multimodality in the VR presence. This leads us to a certain difficulty in generalizations which is well-grounded by our egocentric audio perspective. In our proposal of theoretical framework, the hierarchies initially identified can change dynamically.</p><p class="Para" id="Par50">Ernst and Bülthoff’s theory [<span class="CitationRef"><a epub:type="biblioref" href="#CR41" role="doc-biblioref">41</a></span>] suggests how our brain combines and merges different sources of sensory information. The authors described two main strategies: sensory combination and integration. The former aims at maximizing the information extraction from each modality in a non-redundant manner. The second aims at finding congruence and reducing variability in the redundant sensory information in search of greater perceptual reliability. Both strategies consider a bottom-up approach to sensory integration. In particular, the concept of <em class="EmphasisTypeItalic ">dominance </em>is associated with perceptual reliability from each specific sensory modality given the specific stimulus. This means that the main research challenge for SIVE is not only to foster research aimed at understanding how humans process information from different sensory channels (psychophysics and neuroscience domains), but especially how multimodal VEs should distribute the information load to obtain the best experience for each individual. Accordingly, we assume that each listener has <strong class="EmphasisTypeBold ">personal optimization strategies</strong> to extract meaning from redundant sensory information distributions. The VR technology can improve if and only if it can have a sort of dialogue with the listener to understand such a natural mixture of information.</p><p class="Para" id="Par51">The design process of multimodal VEs must also constantly take into account the limitations, i.e., the characterization, of the VR technologies with the aim at creating real-time interactions with the listener. According to Pai [<span class="CitationRef"><a epub:type="biblioref" href="#CR108" role="doc-biblioref">108</a></span>], interaction models can be described as a trade-off between accuracy and responsiveness. Increasing the descriptive power and thus the accuracy of a model for a certain phenomenon leads to processing more information before providing an output in response to a parametric configuration. It comes at the price of higher latency for the system. For <strong class="EmphasisTypeBold ">multisensory models</strong> that should synchronize different sensory channels, this is crucial and has to be carefully balanced with many other concurrent goals.</p><p class="Para" id="Par52">Understanding interactions between humans and their everyday physical world should not only inspire the design of natural multimodal interfaces but should be directly explored into VE models and simulation algorithms. This message is strongly supported by Chap. <span class="ExternalRef"><a href="478239_1_En_10_Chapter.xhtml"><span class="RefSource">10</span></a></span> and our theoretical framework fully integrates this vision by trying to further extend this perspective to non-human agents. The role of the digital simulation and the computer behind it is participation and discovery for the listener. They constitute a complex system whose interactions contribute to the dynamic definition of non-linear <span id="ITerm11">narratives</span> and causal relationships that are crucial for immersive experiences. The application contexts of the interactive simulations instruct the trade-off between the accuracy and responsiveness models. Hence, the knowledge of the perceptual-cognitive listener capabilities emerges as active transformations in multimodal digital VR experiences.</p></section><section class="Section1 RenderAsSection1" id="Sec3"><h2 class="Heading"><span class="HeadingNumber">1.3 </span>Egocentric Audio</h2><p class="Para" id="Par53">A large body of research in computational acoustics focused on the technical challenges of quantitative accuracy characterizing engineering applications, simulations for acoustic design, and treatment in concert halls. Such simulations are very expensive in terms of computational resources and memory, so it is not surprising that the central role of perception in rendering has gradually come into play. The search for lower bounds such as the perceptually authentic audio-visual renderings can be achieved (see Chap. <span class="ExternalRef"><a href="478239_1_En_5_Chapter.xhtml"><span class="RefSource">5</span></a></span> for a more detailed discussion). Continuous knowledge exchange between psychophysical research and interactive algorithms development allows to test new hypotheses and propose responsive VR solutions. It is worthwhile to mention the topic of artificial reverberations and modeling of the reverberation time aiming to provide a sense of presence through the main spatial qualities of a room, e.g., its size [<span class="CitationRef"><a epub:type="biblioref" href="#CR83" role="doc-biblioref">83</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR147" role="doc-biblioref">147</a></span>].</p><p class="Para" id="Par54">In the context of SIVE, we could review and adapt the three paradigm shifts, or “waves” in HCI mentioned by Harrison [<span class="CitationRef"><a epub:type="biblioref" href="#CR64" role="doc-biblioref">64</a></span>], which still coexist and are at the center of research agendas for different scientific communities. The first wave considers the optimization of interaction in terms of the human factor in an engineered system. We could mention as an example the ergonomic, but generic, “ one fits all” solutions of dummy-heads and binaural microphones for capturing acoustic scenes [<span class="CitationRef"><a epub:type="biblioref" href="#CR110" role="doc-biblioref">110</a></span>]. The second wave introduces a connection between man and machine in terms of information exchange, looking for similarities and common ground in decision-making processes, e.g., memory and cognition. The structural inclusion of non-linearities and auditory Just-Noticeable Differences (JNDs) to determine the amount of information to be encoded for gesture sonification is an example of this direction [<span class="CitationRef"><a epub:type="biblioref" href="#CR38" role="doc-biblioref">38</a></span>]. Finally, the third paradigm shift considers interaction as a situated, embodied, and social experience, characterized by emotions and complex relations encountered in everyday life. We could place here many of the case studies collected in this volume (Parts III and IV). To this regard, the extracted patterns or best practices are often very specific to each study and listeners’ groups, e.g., musician vs. non-musician (Chap. <span class="ExternalRef"><a href="478239_1_En_9_Chapter.xhtml"><span class="RefSource">9</span></a></span>).</p><p class="Para" id="Par55">From developments in phenomenological [<span class="CitationRef"><a epub:type="biblioref" href="#CR93" role="doc-biblioref">93</a></span>] and, more recently, post-phenomenological <span id="ITerm12">thinking</span> [<span class="CitationRef"><a epub:type="biblioref" href="#CR74" role="doc-biblioref">74</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR150" role="doc-biblioref">150</a></span>], we will therefore develop the egocentric <span id="ITerm13">audio</span> perspective. The key principle is the shift between interaction between defined objects to intra-<span id="ITerm14">action</span> within a phenomenon whose main actors are human and non-human agents. Boundaries between actors are fluidly determined, similarly to the Gibsonian ecological theory of perception [<span class="CitationRef"><a epub:type="biblioref" href="#CR54" role="doc-biblioref">54</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR55" role="doc-biblioref">55</a></span>]. Even though this is a shift from an anthropocentric and user-centered view toward a system of enactive relations and associations in the immersive world of sounds, we chose the term egocentric to emphasize the <strong class="EmphasisTypeBold ">spatial anchoring</strong> between humans and technology in the self-knowledge constitution.</p><div class="Para" id="Par56">It would be useful also referring to the concept of <em class="EmphasisTypeItalic ">ambiguity</em> by the philosopher Maurice Merleau-Ponty that says that all experiences are ambiguous, composed of things that do not have defined, identifiable essence, but rather by open or flexible styles or patterns of interactions and developments [<span class="CitationRef"><a epub:type="biblioref" href="#CR93" role="doc-biblioref">93</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR123" role="doc-biblioref">123</a></span>]. Starting from an egocentric spatial perspective of immersive VR, the learning and transformation processes of the listeners occur when their attention is guided toward external virtual sounds, e.g., the out-of-the-head and externalized stimuli. This allows them to achieve meaningful discoveries also for their auditory digital twins. Accordingly, the experience mediated by a non-self, i.e., auditory simulation of VEs, is shaped (i) by the past experience of the listener and the digital twin indistinctly acquired from a physical or cybernetic world in a constructivist sense, (ii) by the physical-acoustic imprinting induced or simulated by the body, head and ears, and (iii) by active and adaptive processes of perceptual re-learning [<span class="CitationRef"><a epub:type="biblioref" href="#CR57" role="doc-biblioref">57</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR160" role="doc-biblioref">160</a></span>] induced by <strong class="EmphasisTypeBold ">a symbiosis with technology</strong>. Figure <span class="InternalRef"><a href="#Fig3">1.3</a></span> schematizes and simplifies this relationship between man-technology-world from which the listener acquires meaning. As pointed out by Vindenes and Wasson [<span class="CitationRef"><a epub:type="biblioref" href="#CR151" role="doc-biblioref">151</a></span>], experiences are mediated in a situated way from the subjectivity of the listener which constitutes herself in relation to the objectivity of the VE. Having placed the physical and virtual worlds at the same level yields to similar internal representations for the listener and her digital twin, allowing us to promote the transformative role of VR experiences for a human-reality relationship altered after exposure.<figure class="Figure" id="Fig3"><div class="MediaObject" id="MO3"><img alt="" src="../images/478239_1_En_1_Chapter/478239_1_En_1_Fig3_HTML.png" style="width:23.35em"/></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 1.3</span><p class="SimplePara">Technological mediation of the auditory digital twin</p><div class="Credit"><p class="SimplePara">(adapted from Hauser et al. [<span class="CitationRef"><a epub:type="biblioref" href="#CR66" role="doc-biblioref">66</a></span>])</p></div></div></figcaption></figure>
</div><p class="Para" id="Par57">The core of our framework is an ideal <strong class="EmphasisTypeBold ">auditory digital twin</strong><span id="ITerm15"/>: an essential mediator and existential mirror for an egocentric audio perspective. Technology is the mediator of this intentional relationship co-constituting both the listener and her being in the world. From this post-phenomenological perspective of SIVE, we are interested in understanding how the VE relates to the listener and what is the meaning of the VEs for the listener, at the same time. Our main goal is to characterize the mediating action between the listener and the VE by an auditory digital twin. This guardian can reveal the listener’s ongoing reconfiguration through the human-world relationship occurring outside the VR experience.</p><p class="Para" id="Par58">In the remainder of this chapter, we will motivate the opportunity to refer to this non-human entity other than the self and aspiring to be the mediator for the self. This first philosophical excursus of hermeneutical nature allows us to take a forward-looking vision for the SIVE discipline, framing the current state of the art but also including the rapid technological developments and ethical challenges due to the digital <span id="ITerm16">transformation</span>.</p><section class="Section2 RenderAsSection2" id="Sec4"><h3 class="Heading"><span class="HeadingNumber">1.3.1 </span>Spatial Centrality</h3><p class="Para" id="Par59">The three-dimensionality of the action space is one of the founding characteristics of immersive VE. Considering such space of transmission, propagation, and reception of virtually simulated sounds, sonic experiences can assume different meanings and open up to many opportunities.</p><p class="Para" id="Par60">Immersive audio in VR can be reproduced both through headphones and loudspeaker arrays determining a differentiation between listener- and loudspeaker-centric perspectives. The latter seems to decentralize the listener role in favor of a strong correlation between virtual and physical (playback) space. In particular, sound in VEs is decoded for the specific loudspeaker arrangements in the physical world (for a summary of the playback systems refer to Chap. <span class="ExternalRef"><a href="478239_1_En_5_Chapter.xhtml"><span class="RefSource">5</span></a></span>). This setup allows the coexistence of several listeners in the controlled playback space, depending on the so-called sweet spot. However, the VE and the listener-avatar mapping is intrinsically egocentric and multisensory, subordinating a loudspeaker-centric perspective for the simulation of the auditory field to a listener-centric one. Let us try to clarify this idea with a practical example: head movements and the navigation system, e.g., redirected <span id="ITerm17">walking</span> [<span class="CitationRef"><a epub:type="biblioref" href="#CR101" role="doc-biblioref">101</a></span>], determine the spatial reference changes for the real/virtual environment mapping corresponding to the listener’s dynamic exploration. The tracking system could trigger certain algorithmic decisions to maintain the place and plausibility illusions of the immersive audio experience.</p><section class="Section3 RenderAsSection3" id="Sec5"><h4 class="Heading"><span class="HeadingNumber">1.3.1.1 </span>First Person Point of View</h4><p class="Para" id="Par61">In this theoretical framework, we focus on the listener’s perspective, where sound is generated from the first-person point of <span id="ITerm18">view</span> (generally referred to as 1PP). Virtual sounds are shaped by spatial hearing models: auralization takes into account the individual everyday listening experience both in physical-acoustic and non-acoustic terms. Contextual information relate spatial positions between sound events and objects with the avatar virtual body, creating a sense of proximity and meaningful relations for the listener.</p><p class="Para" id="Par62">It is relevant to stress the connection between the egocentric audio perspective and the research field of egocentric <span id="ITerm19">vision</span> that has more than twenty-year history. The latter is a subfield of computer vision that involves the analysis of images and videos captured by wearable cameras, e.g., Narrative Clips<sup><a epub:type="noteref" href="#Fn7" id="Fn7_source" role="doc-noteref">7</a></sup> and GoPro<sup><a epub:type="noteref" href="#Fn8" id="Fn8_source" role="doc-noteref">8</a></sup>, considering an approximation of the visual field due to a 1PP. From this source of information, spatio-temporal visual features can be extracted to conduct various types of recognition tasks, e.g., of objects or activities [<span class="CitationRef"><a epub:type="biblioref" href="#CR100" role="doc-biblioref">100</a></span>], and analysis of social interactions [<span class="CitationRef"><a epub:type="biblioref" href="#CR2" role="doc-biblioref">2</a></span>]. The egocentric audio perspective originates from the same 1PP in which both space and time of events play a fundamental role in the analysis and synthesis of sonic interactions. Furthermore, we stress the idea that all hypotheses and evaluations in both egocentric vision and audition are individually shaped around a human actor. However, our vision does not focus exclusively on the analysis of the listener behaviors but includes <strong class="EmphasisTypeBold ">generative aspects</strong> thanks to the technological mediation of the spatial relations between humans and VEs (these aspects will be extensively discussed in Sect. <span class="InternalRef"><a href="#Sec8">1.3.2</a></span>).</p><p class="Para" id="Par65">Using a simplification adopted in Chap. <span class="ExternalRef"><a href="478239_1_En_2_Chapter.xhtml"><span class="RefSource">2</span></a></span> concerning the work by Stockburger [<span class="CitationRef"><a epub:type="biblioref" href="#CR140" role="doc-biblioref">140</a></span>] on sounds in video games, we can distinguish two categories for sound effects: (i) those related to the avatar’s movements and actions (e.g., footsteps, knocking on a door, clothing noises, etc.) and (ii) the remaining effects produced by the VE. In this simple distinction, it is important to note that all events are echoic, i.e., they produce delays and resonances imprinted by the spatial arrangements of the avatar-VE configurations depending on the acoustical characteristics of the simulated space. Moreover, all events should be interpreted by the listener’s memory which is shaped by the natural everyday reality.</p><p class="Para" id="Par66">Finally, it is worthwhile to notice that egocentric 1PP poses novel challenges in the field of cinematic VR narration or more generally of storytelling in VR. Gödde et al. [<span class="CitationRef"><a epub:type="biblioref" href="#CR56" role="doc-biblioref">56</a></span>] identified immersive audio as an essential element able to capture attention on events/objects outside the field of view. The distinction between the active role of the listener interacting with the <span id="ITerm20">narrative</span> or passive role as an observer raises interesting questions about the spatial and temporal positioning of scenic elements. The balance between environment, action, and narration is delicate. Citing Gödde and collaborators, one <em class="EmphasisTypeItalic ">“can only follow a narrative sufficiently when temporal and spatial story density are aligned with each other”.</em> Hence, the spatio-temporal alignment of sound is crucial.</p><p class="Para" id="Par67">For most researchers interested in sound, from the neurological to the aesthetic-communicative level, it is clear that while the visual object exists primarily in space, the auditory stimulus occurs in time. Therefore, it is not surprising that in order to speak of spatial centrality in audio we need to consider presence, the central attribute for a VR experience. In his support of a representational view of it, Loomis [<span class="CitationRef"><a epub:type="biblioref" href="#CR88" role="doc-biblioref">88</a></span>] cites two scientists with two opposite opinions: Willian Warren and Pavel Zahorik, the first an expert in visual VR and the latter in acoustic VR. The former supports a rationalist view of representational realism and direct perception [<span class="CitationRef"><a epub:type="biblioref" href="#CR154" role="doc-biblioref">154</a></span>], while the latter supports the ecological perspective in the <strong class="EmphasisTypeBold ">fluidity in perception-action</strong> [<span class="CitationRef"><a epub:type="biblioref" href="#CR159" role="doc-biblioref">159</a></span>].<sup><a epub:type="noteref" href="#Fn9" id="Fn9_source" role="doc-noteref">9</a></sup> The second perspective supports the concept of <span id="ITerm21">enaction</span> such that it is impossible to separate perception from action in a systematic way. Perception is inherently active and reflexive in the self. Recalling Varela, another leading supporter of this perspective [<span class="CitationRef"><a epub:type="biblioref" href="#CR148" role="doc-biblioref">148</a></span>], experience does not happen within the listener but is instead enacted by the listener by exploring the environment. Accordingly, we consider an embodied, environmentally situated perceiver where sensory and motor processes are inseparable from the exploratory action in space. At first glance, such a view restricts experiences to only those generated by specific motor skills which are in turn induced by biological, psychological, and cultural context. However, it is generally not true in a digital-twin-driven VE (see Sect. <span class="InternalRef"><a href="#Sec13">1.4.3</a></span>).</p></section><section class="Section3 RenderAsSection3" id="Sec6"><h4 class="Heading"><span class="HeadingNumber">1.3.1.2 </span>Binaural Hearing</h4><p class="Para" id="Par69">The geometric and material features of the environment are constituent elements of the virtual world that must be simulated in a plausible way for that specific listener. First of all, the listener-environment coupling is unavoidable and must guarantee as good sound localization performances as to maintain immersiveness. It has to especially avoid the inside-the-head spatial collapse, i.e., when the virtual sound stimuli are perceived inside the head, a condition opposite to the natural listening experience of outside-the-head localization for surrounding sound sources, also called <span id="ITerm22">externalization</span> [<span class="CitationRef"><a epub:type="biblioref" href="#CR131" role="doc-biblioref">131</a></span>]. Externalization can be considered a necessary but not sufficient condition for the place illusion, being immersed in that virtual acoustic space. For a recent review of the literature on this topic, Best et al. [<span class="CitationRef"><a epub:type="biblioref" href="#CR8" role="doc-biblioref">8</a></span>] suggest that ambient reverberation and sensorimotor contingencies are key indicators for eliciting a sense of externalization, whereas HRTF personalization and consistent visual information may reinforce the illusion under specific circumstances. However, the intra-action between these factors is so complex that <strong class="EmphasisTypeBold ">no univocal priority principles</strong> can be applied. Accordingly, we should explore dynamic relations depending on specific links between evolving states of the listener-VE system during the VR experiences. Moreover, huge individual-based differences in the perception of externalization require in-depth exploration of several individual factors such as monaural and binaural HRTF spectral features, temporal processes of adaptation [<span class="CitationRef"><a epub:type="biblioref" href="#CR27" role="doc-biblioref">27</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR65" role="doc-biblioref">65</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR146" role="doc-biblioref">146</a></span>].</p><p class="Para" id="Par70">Binaural audio and spatial <span id="ITerm23">hearing</span> have been well-established research fields for more than 100 years and have received relevant contributions from information and communications technologies (ICT) and in particular from digital signal processing. Progress in digital simulations has made it possible to replicate with increasing accuracy the acoustic transformation by the body of a specific listener with very high spatial resolution up to sub-millimeter grids for the outer ear [<span class="CitationRef"><a epub:type="biblioref" href="#CR113" role="doc-biblioref">113</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR114" role="doc-biblioref">114</a></span>]. This process generates acoustically personalized HRTFs so that the rendering of immersive audio matches the listener’s acoustic characterization (<em class="EmphasisTypeItalic ">System-to-User adaptation</em> in Chap. <span class="ExternalRef"><a href="478239_1_En_4_Chapter.xhtml"><span class="RefSource">4</span></a></span>). On the opposite side, the VE can train and guide the listener in a process of <em class="EmphasisTypeItalic ">User-to-System adaptation</em> by designing ad-hoc procedures for continuous interaction with the VE to induce a persistent <strong class="EmphasisTypeBold ">recalibration of the auditory system</strong> to non-individual HRTFs.<sup><a epub:type="noteref" href="#Fn10" id="Fn10_source" role="doc-noteref">10</a></sup> These two approaches can be considered two poles between which one can define several mixed solutions. This dualism is brilliantly exposed and analyzed in Chap. <span class="ExternalRef"><a href="478239_1_En_4_Chapter.xhtml"><span class="RefSource">4</span></a></span>.</p></section><section class="Section3 RenderAsSection3" id="Sec7"><h4 class="Heading"><span class="HeadingNumber">1.3.1.3 </span>Quality of the Mediated Experience</h4><p class="Para" id="Par72">Since our theoretical framework aims to go beyond user-centricity, we approach the space issue from different perspectives, both user and technology perspectives, respectively. However, all points of view remain ecologically anchored to the egocentric 1PP of the listener giving rise to a fundamental question: how can we obtain high-quality sonic interactions for a specific listener-technology relation? In principle, many <strong class="EmphasisTypeBold ">quality assessment procedures</strong> might be applied to immersive VR systems. However, there is no adequately in-depth knowledge of the technical-psychological-cognitive relationship regarding spatial hearing and multisensory integration processes linked to plausibility and <span id="ITerm24">technological</span> mediation.</p><p class="Para" id="Par73">On the other hand, a good level of standardization has been achieved for the perceptual evaluation of audio systems. For instance, the ITU recommendations focus on the technical properties of the system and signal processing algorithms. Chapter <span class="ExternalRef"><a href="478239_1_En_5_Chapter.xhtml"><span class="RefSource">5</span></a></span> introduces the <em class="EmphasisTypeItalic ">Basic Audio Qualities</em> used for telecommunications and audio codecs, commonly adopted in the evaluation of spatial audio reproduction systems. On the other hand, the evaluation of the listening experience quality, called <em class="EmphasisTypeItalic ">Overall Listening Experience</em> [<span class="CitationRef"><a epub:type="biblioref" href="#CR125" role="doc-biblioref">125</a></span>], is also introduced, considering not only system technical performances but also listeners’ expectations, personality, and their current state. All these factors influence the listening of specific audio content. A related measure can be the level of audio detail (LOAD) [<span class="CitationRef"><a epub:type="biblioref" href="#CR39" role="doc-biblioref">39</a></span>] that attempts to manage the available computational power, the variation of spatio-temporal auditory resolution in complex scenes, and the perceptual outcome expected by the listener, in a dynamically adaptive way.</p><p class="Para" id="Par74">Chapter <span class="ExternalRef"><a href="478239_1_En_2_Chapter.xhtml"><span class="RefSource">2</span></a></span> provides an original discussion on audio “quality scaling” in VR simulations, drawing the following conclusion: there is neither an unambiguous definition nor established models for such issues. It suggests that understanding the listener-simulation-playback relations is an open challenge, extremely relevant to SIVE. In general, the most commonly used approach is the <strong class="EmphasisTypeBold ">differential diagnosis</strong>, allowing the qualities of VR systems to emerge from different quantitative and qualitative measurements. Several taxonomies for audio qualities or sound spatialization have given rise to several attribute collections, e.g., semantic analysis of expert surveys and expert focus groups (see Chap. <span class="ExternalRef"><a href="478239_1_En_5_Chapter.xhtml"><span class="RefSource">5</span></a></span> on this). It is worthwhile to mention that a substantial body of research in VR is devoted to explore the connections between VR properties such as authenticity, immersion, sense of presence and neurophysiological measurements, e.g., electroencephalogram, electromyography, electrocardiogram, and behavioral measurements, e.g., reaction <span id="ITerm25">time</span>, <span id="ITerm26">kinematic</span> analysis.</p><p class="Para" id="Par75">To summarize, this differentiation tries to capture all those factors that lead to a high level of presence: sensory plausibility, naturalness in the interactions, meaning and relevance of the scene, etc. Moreover, the sense of presence in a VR will remain limited if the experience is irrelevant to the listener. If the listener-environment relation is weak, the mediating action of the immersive technology might result in a break in <span id="ITerm27">presence</span> that can hardly be restored after a pause [<span class="CitationRef"><a epub:type="biblioref" href="#CR136" role="doc-biblioref">136</a></span>]. These cognitive illusions depend, for example, on the level of hearing training, familiarity with a stimulus/sound environment. All these aspects reinforce the term egocentric again, grounding auditory information to a reference system that is naturally processed and interpreted in 1PP. However, SIVE challenges go far beyond two opposing points of view, i.e., user-centered and technology-centered. In this chapter, we offer a first attempt at a systemic interpretation of the phenomenon.</p></section></section><section class="Section2 RenderAsSection2" id="Sec8"><h3 class="Heading"><span class="HeadingNumber">1.3.2 </span>Entanglement HCI</h3><p class="Para" id="Par76">Heidegger’s phenomenology aims to overcome mind-body dualism by introducing the notion of “Dasein” which requires an embodied mind to be in the world [<span class="CitationRef"><a epub:type="biblioref" href="#CR67" role="doc-biblioref">67</a></span>]. The concept of <span id="ITerm28">embodiment</span> became central to the third wave of HCI, e.g., in relation to mobile and tangible user interfaces [<span class="CitationRef"><a epub:type="biblioref" href="#CR64" role="doc-biblioref">64</a></span>]. More recently, the bodily element has been incorporated into the theoretical framework of <span id="ITerm29">somaesthetics</span> to explain aesthetic experiences of interaction and into <strong class="EmphasisTypeBold ">design principles for bodily interaction</strong> [<span class="CitationRef"><a epub:type="biblioref" href="#CR71" role="doc-biblioref">71</a></span>]. Designers are encouraged to participate with their lived, sentient, subjective, purposive bodies in the process of creating human-computer interactions, either by improving their design skills and sensibilities, or by providing an added value of aesthetic pleasure, lasting satisfaction, and enjoyment to users. These elements are summarized in Chap. <span class="ExternalRef"><a href="478239_1_En_7_Chapter.xhtml"><span class="RefSource">7</span></a></span>, which provides a useful distinction of perspectives for interaction <span id="ITerm30">design</span>: the first-person, second-person, and third person design perspective. The latter is equivalent to an observer approach to design such as considering the common practices, e.g., interview administration, subjective evaluations, and data analysis acquired from a variety of sensors. The second-person is equivalent to the user-centered and co-design approach between the user’s perspective and the designer’s attempt to step into the shoes of someone else. On the other hand, soma design principles embrace a first-person perspective, we would argue egocentric, even for designers, who are actively involved with their bodies during each step of the interaction design process of an artifact or simulation. They explicitly become actors themselves with the result of shaping a felt and lived experience for other actors.</p><p class="Para" id="Par77">In the movement computing work by Loke and Robertson [<span class="CitationRef"><a epub:type="biblioref" href="#CR87" role="doc-biblioref">87</a></span>], the authors introduced another perspective distinction relevant here. The mover (first-person perspective) and the observer (third-person perspective) are explicitly joined by <strong class="EmphasisTypeBold ">the machine perspective</strong>. The role of technology is pivotal for the interactions with digital movement information and, in particular, for the process of attributing meaning based on user input. This perspective requires mapping data from sensing technologies into meaningful representations for the observer and the mover. It is worthwhile to note that machines capture the qualities of movement with considerable losses in terms of spatial, temporal, or range resolution, making the comprehension of such limitations on interaction design essential. We need to explore the various perspectives, not in a mutually exclusive way, but dynamically managing the analysis of the various points of view in every immersive experience.</p><p class="Para" id="Par78">According to Verbeek [<span class="CitationRef"><a epub:type="biblioref" href="#CR150" role="doc-biblioref">150</a></span>], human-world relations are enacted through technology. Thus, man and technology constitute themselves as actors in a <strong class="EmphasisTypeBold ">fluid reconfiguration</strong>. A practical example in the field of music perception considers a drummer who changes her latency perception the more she plays the musical instrument [<span class="CitationRef"><a epub:type="biblioref" href="#CR86" role="doc-biblioref">86</a></span>]. The action of playing the drum changes the relationships that she has with the instrument itself, with the self, and with temporal aspects of the world, e.g., reaction times and synchronizations.</p><p class="Para" id="Par79">The recent proposal of a post-phenomenological framework by Vindenes [<span class="CitationRef"><a epub:type="biblioref" href="#CR151" role="doc-biblioref">151</a></span>] is based on Verbeek’s concept of technological <span id="ITerm31">mediation</span>, which identifies several human-technology relationships including immersion in smart environments, ambient intelligence, or persuasive technologies. In particular, for the latter case, VR plays a central role co-participating within a mixed intentionality between humans and technology. Accordingly, Verbeek introduced the idea of composite intentionality for <span id="ITerm32">cyborgs</span> [<span class="CitationRef"><a epub:type="biblioref" href="#CR149" role="doc-biblioref">149</a></span>], a cooperation between human and technological intentionality with the aim to reveal a (virtual) reality that can only be experienced by technologies, by <strong class="EmphasisTypeBold ">making accessible technological intentionalities to human intentionality</strong>. We can argue that the world and the technology become one in the immersive simulation that knows the listeners and actively interacts with them. This configuration becomes bidirectional: humans are directed toward technology and technology is directed toward them. Moreover, listeners have the opportunity to access reflective relationships with themselves through VEs. For example, Osimo et al. provided experience of the self through virtual body-swapping in the embodied perspective-taking [<span class="CitationRef"><a epub:type="biblioref" href="#CR106" role="doc-biblioref">106</a></span>]. We must decentralize humans as the sole source of activity and attribute to the material/technological world an active role in revealing new and unprecedented relational actions.</p><p class="Para" id="Par80">This approach opens up new opportunities for “reflexive <span id="ITerm33">intentionality</span>” of the human beings about themselves through the active relation with simulations [<span class="CitationRef"><a epub:type="biblioref" href="#CR5" role="doc-biblioref">5</a></span>]. About this, Verbeek [<span class="CitationRef"><a epub:type="biblioref" href="#CR150" role="doc-biblioref">150</a></span>] classifies the technological influence on humans according to two dimensions: visibility and strength. Some mediations can be hidden but induce strong limitations, while others can be manifest but have a weak impact on humans. There is a deep <span id="ITerm34">entanglement</span> between humans and machines to the extent that there is no human experience that is not mediated through some kind of technology that shapes who we are and what we do in the world. Considering immersive VR technologies, we must speculate on what is a <strong class="EmphasisTypeBold ">locus of agency</strong>: the understanding of the active contributions of each tool in the listener’s actions in VEs. Such an infrastructure must be enactive and re-interpretive of each actor in each circumstance. In other words, there is the opportunity of becoming different actors depending on an active inter-dependence.</p><p class="Para" id="Par81">At this point, recalling the work of Orlikowski [<span class="CitationRef"><a epub:type="biblioref" href="#CR105" role="doc-biblioref">105</a></span>] is twofold. First, she gave the name of <em class="EmphasisTypeItalic ">entanglement</em> theories to those heterogeneous theories that have in common the recognition of the active inter-dependence between socio-technological-material configurations with the consequence of promoting studies of man and technology in a unitary way. Secondly, Orlikowski supported her position with an experimental example of social VR, the Sun Microsystems’ Project Wonderland developed more than a decade ago and, nowadays, it seems more relevant than ever due to the COVID-19 pandemic. We will analyze a similar case in SIVE, supporting our taxonomy in Sect. <span class="InternalRef"><a href="#Sec10">1.4</a></span>. In this section, we focus on entanglement theories that are foundational for our egocentric perspective.</p><p class="Para" id="Par82">The entanglement is the deep connection between men and their tools, having relevant repercussions in the field of human-computer <span id="ITerm35">interaction</span>. In [<span class="CitationRef"><a epub:type="biblioref" href="#CR45" role="doc-biblioref">45</a></span>], Frauenberger provided the following interpretative key: we cannot design computers or interactions, we can work on facilitating certain configurations that enact certain phenomena. Both configurations and phenomena are situated and fluid, but not random. They are causally connected within <strong class="EmphasisTypeBold ">hybrid networks in which human and non-human actors interact</strong>. However, it must be made clear that these actors do not possess fixed representations of their entities, but they exist only in their situated intra-action. This means that their relations and configurations are dynamically defined by the so-called <em class="EmphasisTypeItalic ">agential <span id="ITerm36">cuts</span>
</em> that draw the boundaries between entities during phenomena. In this network of associations, each configuration change is equivalent to a newly enacted phenomenon where new agential cuts are redefined or create new actors. Hence, the term <span id="ITerm37">agency</span> refers to a performative mechanism of boundary definition and constitution of the self. Together with the post-phenomenological notion of technological mediation, entangled HCI provides a lens able to interpret the increasingly fuzzy boundaries between humans, machines, and their distribution of agency.</p><p class="Para" id="Par83">The sonic information from intentional active listening is anchored to an egocentric perspective of spatiality that allows the understanding of an acoustic scene transformed by the listener’s actions/movements. This process can be mathematically formalized with the active <span id="ITerm38">inference</span> approach by Karl Friston and colleagues [<span class="CitationRef"><a epub:type="biblioref" href="#CR46" role="doc-biblioref">46</a></span>] and their recent enactive interpretation [<span class="CitationRef"><a epub:type="biblioref" href="#CR115" role="doc-biblioref">115</a></span>]. Their computational framework quantitatively integrates sensation and prediction through probability and generative models optimizing the so-called <em class="EmphasisTypeItalic ">free-energy principle</em>, i.e., an optimization problem of a function of the beliefs and expectations. Following this line of thought both philosophically and mathematically, we argue that immersive audio technologies are capable of contributing to the listener’s internal representation in both spatial and semantic terms, eliciting a strong sense of presence in VR [<span class="CitationRef"><a epub:type="biblioref" href="#CR12" role="doc-biblioref">12</a></span>]. Just as we cannot clearly distinguish between listener and real environment, the more we cannot distinguish between listener and VE.</p><p class="Para" id="Par84">Therefore, the sonic interaction design in <span id="ITerm39">VEs</span> is an intra-<span id="ITerm40">action</span> between technology, concepts, visions, designers, and listeners that produce certain configurations and agential cuts. According to the sociological actor-network <span id="ITerm41">theory</span> [<span class="CitationRef"><a epub:type="biblioref" href="#CR28" role="doc-biblioref">28</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR85" role="doc-biblioref">85</a></span>], the network of associations characterizes the ways in which materials join together to generate themselves. Prior knowledge also becomes an actor in such a network that shapes, constrains, enables, or promotes certain activities. For example, modeling the listener’s acoustic contribution with measurements from a dummy head induces a cut that shapes the use cases and VR experiences. Similarly, agential cuts are performed based on knowledge from other studies. For instance, the auditory feedback supports the plausibility of footstep synthesis or the strategies employed in the definition of time windows for synchronous and embodied sensory integration [<span class="CitationRef"><a epub:type="biblioref" href="#CR122" role="doc-biblioref">122</a></span>]. Moreover, the physical and design features of the technology also contribute to determining what is feasible: e.g., the differentiation of playback systems for spatial audio results in differentiation in the quality of the experience (see Chap.  <span class="ExternalRef"><a href="478239_1_En_11_Chapter.xhtml"><span class="RefSource">11</span></a></span>).</p><p class="Para" id="Par85">In the entanglement within the relational network of listener-reality-simulation, configurations and actors are dynamically defined in a situated and embodied manner. In the process of configuring and reconfiguring actors, designing various aspects, and operating agential cuts <strong class="EmphasisTypeBold ">new knowledge is produced</strong> that causally links the enactment of the technological design to the phenomenon created [<span class="CitationRef"><a epub:type="biblioref" href="#CR45" role="doc-biblioref">45</a></span>]. This means that this knowledge has several forms, one resides in the technological artifact itself, i.e., in the VR simulation. In a more general sense, we could argue that exploring the evolution in the network configurations and actors enables an active search for the egocentrically meaningful experience. In line with this, agency and its responsibilities are not the prerogative of the listener or the technology but reside in their intra-actions.</p></section><section class="Section2 RenderAsSection2" id="Sec9"><h3 class="Heading"><span class="HeadingNumber">1.3.3 </span>Auditory Digital Twin</h3><div class="Para" id="Par86">From entanglement theories, we inherit a series of open questions that guides our reflection on the SIVE research field. Let’s consider the immersive VR simulation as the digital artifact co-defining itself with the listener who experiences it.<blockquote class="BlockQuote"><p class="Para">How can certain transformative actions and interactions be programmed?</p><p class="Para" id="Par87">Who/what is the mediator, if any, in the relationship between the physical world and the VE?</p><p class="Para" id="Par88">How should such a mediator act?</p></blockquote>Of particular interest here is Schultze’s interpretation of the <span id="ITerm42">avatar</span> [<span class="CitationRef"><a epub:type="biblioref" href="#CR126" role="doc-biblioref">126</a></span>]: a dynamic self-representation for the user, a form of situated presence that is variably implemented. Sometimes the avatar is seen as a separate entity, behaving independently of the user. Sometimes the listener inhabits the avatar, merging with it to such an extent that they feel completely immersed and present in the virtual space. From this variety of instances, definitions of identity (avatar vs. self), agency (technology vs. human), and the world (physical vs. virtual) are fluid and enacted depending on the situation. Moreover, we argue that avatars and listeners know very little about each other. Such consideration strengthens the individual experience that determines one tendency over the other (separation vs. union with an avatar) with difficult predictions and poorly generalizable interpretations. Consequently, the user characterization in human-centered design is somehow included here [<span class="CitationRef"><a epub:type="biblioref" href="#CR76" role="doc-biblioref">76</a></span>]. However, our view promotes meaningful human-technology relationships in a bidirectional manner: not only personalized user experiences, but <strong class="EmphasisTypeBold ">experiences able to shape who we really want to be</strong>.</div><p class="Para" id="Par89">The communication between the avatar and the listener, the virtual and the physical is challenging. Considering the avatar as part of a VE configuration, we can formulate one of the initial questions: if we can handle mediation, where/who is in charge of that?</p><p class="Para" id="Par90">Our performative perspective is questioning the a priori and fixed distinctions of certain representationalism between avatar and self, technology agency and listener, physical reality, and virtuality. These boundaries have to be drawn in situated and embodied action, which makes them dynamic and temporary. The exploration of how, when, and why agential cuts define boundaries of identity, agency, and environments is the core of our theoretical framework.</p><p class="Para" id="Par91">We want to give a digital form to the philosophical question of the <em class="EmphasisTypeItalic ">locus of agency</em>: we envision a meta-environment with technological-digital nature, which is the guardian, careful observer, and lifeblood for the dialogue and participation of each actor. Its name is the <strong class="EmphasisTypeBold ">auditory digital twin</strong><span id="ITerm43"/>. In an egocentric perspective, it takes shape around the listener, i.e., the natural world that is meaningful to her. Why twin? Because this term recalls the idea of the deep connection between two different and distant entities or persons, commonly grounded by similarities, e.g., the DNA or a close friendship. Although the adjective auditory would seem to restrict our idea to the sound component, the framework ecologically extends to the multisensory domain by considering the intrinsic multisensory nature of VR. For these reasons, we will provide an audio-first perspective, sometimes sacrificing the term auditory in favor of a more readable and synthetic expression without loss of information, i.e., (auditory) digital twin.</p><p class="Para" id="Par92">Technical aspects of an artifact can be used to recreate a virtualized version or digital simulation of the artifact itself in the so-called virtual prototyping process [<span class="CitationRef"><a epub:type="biblioref" href="#CR90" role="doc-biblioref">90</a></span>]. Similarly, perceptual and cognitive aspects might serve to obtain digital replicas of biological systems, also referred to as a bio-digital twin in the field of personalized medicine [<span class="CitationRef"><a epub:type="biblioref" href="#CR23" role="doc-biblioref">23</a></span>]. The real person/machine provides the data that gives shape to the virtual one. In the case of humans, the process of <strong class="EmphasisTypeBold ">quantified <span id="ITerm44">self</span>
</strong> [<span class="CitationRef"><a epub:type="biblioref" href="#CR89" role="doc-biblioref">89</a></span>] supports the modeling of the virtual digital twin, an algorithmic assistant in decision-making. Implications of the digital twin paradigm are already envisioned in [<span class="CitationRef"><a epub:type="biblioref" href="#CR40" role="doc-biblioref">40</a></span>]. They range from the continuous monitoring of patient health to the management of the agency in a potentially immortal virtual agent.</p><div class="Para" id="Par93">In the scientific literature, the most common definition of a digital twin is related to a digital replica. However, we would like to provide a significant imprint to our idea of the auditory digital twin as a <strong class="EmphasisTypeBold ">psycho-socio-cultural-material objectified actor-network with agential participation</strong>. As depicted in Fig. <span class="InternalRef"><a href="#Fig4">1.4</a></span>, all digitally objectifiable configurations related to listener profile, VE, HW/SW technology, design, ethical impact, etc. are made available to the digital twin so that it can actively participate intra-acting with system states.<figure class="Figure" id="Fig4"><div class="MediaObject" id="MO4"><img alt="" src="../images/478239_1_En_1_Chapter/478239_1_En_1_Fig4_HTML.png" style="width:28.18em"/></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 1.4</span><p class="SimplePara">A schematic representation of the different sound elements needed to create an immersive sonic experience. Colored lines identify the differences compared to the scheme proposed in [<span class="CitationRef"><a epub:type="biblioref" href="#CR128" role="doc-biblioref">128</a></span>]. In particular, this representation focuses on the central role of the auditory digital twin as a quantifiable <em class="EmphasisTypeItalic ">locus of agency</em> in an active relationship with all actors of a VR experience. The green arrow identifies the participatory relationship between the listener and the digital twin in its performative formation of individual self-knowledge</p></div></figcaption></figure>
</div><div class="Para" id="Par94">To understand the central role of the digital twin in SIVE, we provide some practical examples:<div class="UnorderedList"><ul class="UnorderedListMarkBullet"><li><p class="Para" id="Par95"><strong class="EmphasisTypeBold ">Links to setup configurations</strong>—Body movement tracking opens up numerous opportunities for dynamic rendering and customization of the listener’s acoustic contribution in harmony between the real and the virtual body, i.e., the avatar’s body. Real-time monitoring of the motion <span id="ITerm45">sensors</span> is crucial to avoid a negative impact on responsiveness.</p></li><li><p class="Para" id="Par96"><strong class="EmphasisTypeBold ">Links to listener configurations</strong>—Adaptation and accommodation processes are strongly situated in the task. Assuming the unavailability of individual HRTF measurements, the best HRTF model requires a dynamic analysis of each task/context in a mutual learning perspective between the listener and the digital twin.</p></li><li><p class="Para" id="Par97"><strong class="EmphasisTypeBold ">Links to environment configurations</strong>—Persuasion of a VE for a listener behavioral change depends on social and cultural resonances within the listener. The distribution of agency in a music-induced mood has to be analyzed with particular attention. Again, certain immersive gaming experiences or role-playing may be beneficial for some listeners, to be avoided for others.</p></li><li><p class="Para" id="Par98"><strong class="EmphasisTypeBold ">Links to configurations of others</strong>—Other entities, e.g., virtual agents or avatars guided by other listeners, populate VEs. To manage confrontation and sharing activities, the intra-action between a larger number of digital twins must be consciously encouraged.</p></li></ul></div>
</div><p class="Para" id="Par99">All these configurations are not independent but are always interconnected with each other. Of particular relevance here, we can consider the externalization of sound sources. The level of externalization depends on customization techniques of the spatial audio rendering, the acoustic information of the virtual room, the sensory coherence and synchronicity, and the familiarity with the situation [<span class="CitationRef"><a epub:type="biblioref" href="#CR8" role="doc-biblioref">8</a></span>]. A coordination action of setup, environment, and listener(s) is needed. The presence in VR experiences will be the result of all these fluid intra-connections.</p><p class="Para" id="Par100">Suchman posed a highly relevant question in [<span class="CitationRef"><a epub:type="biblioref" href="#CR141" role="doc-biblioref">141</a></span>]: how can we consider all these configurations in such a way that we can act responsibly and productively with and through them? To answer, we must deal with the participation issues for all involved actors.</p><p class="Para" id="Par101">The egocentric perspective requires us to start from the listener and her experience. The scientific literature already tells us that memory, comprehension, and human performance benefit considerably from these VEs, especially in guided or supervised tasks involving human or digital agents [<span class="CitationRef"><a epub:type="biblioref" href="#CR29" role="doc-biblioref">29</a></span>]. Let us focus on the series of actions triggered by an active role of agents. In [<span class="CitationRef"><a epub:type="biblioref" href="#CR31" role="doc-biblioref">31</a></span>], Collins analyzed the player role in the audio design of video games. The participatory nature of video games potentially leads to the creation of additional or completely new meanings compared to those originally intended by the creators and their <span id="ITerm46">storytelling</span>. Hence, there is a change not only in the reception but also in the transmission in the communication of auditory information. The player becomes a co-transmitter of information introducing non-linearities in the experience that propagate throughout the agents’ chain of activity, triggering feedback and generating further non-linearities.</p><p class="Para" id="Par102">In this respect, Frauenberger’s entanglement HCI (Sect. <span class="InternalRef"><a href="#Sec8">1.3.2</a></span>) suggests abandoning a user-centered design of the digital artifact in favor of <span id="ITerm47">participatory</span>, speculative, and agonistic methods with the ultimate goal of obtaining meaningful relationships and not merely optimized processes relating to the human or the machine pole, or their interaction. It is useful to briefly recall these methods. The agonistic and <strong class="EmphasisTypeBold ">adversarial <span id="ITerm48">design</span>
</strong> employs processes and creates spaces to foster vigorous but polite disputes involving designers’ participation in order to constructively identify inspiring elements of friction [<span class="CitationRef"><a epub:type="biblioref" href="#CR36" role="doc-biblioref">36</a></span>]. On the other hand, the participation in a speculative process through designing <strong class="EmphasisTypeBold ">provotypes</strong><span id="ITerm49"/> aims to provoke a discussion about the technological and cultural future by considering creative, political, and controversial aspects [<span class="CitationRef"><a epub:type="biblioref" href="#CR117" role="doc-biblioref">117</a></span>].</p><p class="Para" id="Par103">The more degrees of freedom in the network configurations, the more behaviors can potentially be stimulated. The relational network should not be hardly controlled because its expressive potential can be exploited through its differentiation. In our opinion, the current immersive audio technologies are struggling to emerge, because they often introduce static agential cuts, justified by audio quality assessments conducted in a reductionistic way. On the contrary, the main goal of the digital twin is to favor the participation of all available configurations. Specific configurations and agential cuts emerge in a speculative, agonistic, and provocative manner so that all actors can benefit from different attempts following <strong class="EmphasisTypeBold ">knowledge <span id="ITerm50">diffraction</span>
</strong> [<span class="CitationRef"><a epub:type="biblioref" href="#CR6" role="doc-biblioref">6</a></span>]. The learning in such fluid and dynamic evolution from one configuration to another is a continuous flow of knowledge that informs the digital twin’s activity. In other words, the digital twin continuously proposes new agential cuts to record and analyze the overall results. A relevant example in SIVE is the co-determination of the attentional focus in selecting the meaningful auditory information for a digital twin facing the cocktail-party <span id="ITerm51">effect</span> [<span class="CitationRef"><a epub:type="biblioref" href="#CR20" role="doc-biblioref">20</a></span>]. The digital twin must be able to guide an active participation with the VE considering listener’s available knowledge extracted by previously experienced and stored scenarios (and agential cuts).</p><p class="Para" id="Par104">The continuous intra-action within the digital twin in relation to a shared and immersive experience is of strong practical relevance within the proposed theoretical framework. This issue offers concrete possibilities for radically changing the way we interact socially in the future, by using digital tools equipped with computational intelligence and <strong class="EmphasisTypeBold ">artificial <span id="ITerm52">intelligence</span> </strong>(AI) algorithms able to manage complex systems [<span class="CitationRef"><a epub:type="biblioref" href="#CR107" role="doc-biblioref">107</a></span>]. The decision-making phase of intelligent algorithms will improve over time, thanks to a dynamic identification and classification of configurations and links in the actor-network. The knowledge can be continuously extracted as a result of computational intra-actions of the <em class="EmphasisTypeItalic ">human-in-the-loop</em> type where the listener can be seen as an agent directly involved in the learning phase, step-by-step influencing cost functions and all other measures [<span class="CitationRef"><a epub:type="biblioref" href="#CR69" role="doc-biblioref">69</a></span>]. More in general, the reinforcement <span id="ITerm53">learning</span> paradigm focuses on long-term goals, defining a formal framework for the interaction between a learning agent and its environment in terms of states, actions, and rewards, hence no explicit definition of desired behavior might be required [<span class="CitationRef"><a epub:type="biblioref" href="#CR35" role="doc-biblioref">35</a></span>]. This process can be accomplished during exposure to a continuous stream of multimodal information like in the case of lifelong learning [<span class="CitationRef"><a epub:type="biblioref" href="#CR109" role="doc-biblioref">109</a></span>], or via interactive annotations and labeling [<span class="CitationRef"><a epub:type="biblioref" href="#CR81" role="doc-biblioref">81</a></span>].</p></section></section><section class="Section1 RenderAsSection1" id="Sec10"><h2 class="Heading"><span class="HeadingNumber">1.4 </span>A Taxonomy for SIVE</h2><p class="Para" id="Par105">An important contribution to the design in VEs comes from practice, e.g., professional reports and testimonials, best practices, or reviews and interpretations of lessons learned in the industry (see Chap. <span class="ExternalRef"><a href="478239_1_En_6_Chapter.xhtml"><span class="RefSource">6</span></a></span> and [<span class="CitationRef"><a epub:type="biblioref" href="#CR76" role="doc-biblioref">76</a></span>]). Taking into account all these inputs, academic studies, new technologies, and commercial user feedback, different communities draw support for their specific users and domains of interest. Within the SIVE field, there is still much work to be done. There is a lack of recommendations and design analysis on creating interfaces, interactions, and environments that fully exploit egocentric sonic information. To unlock such potential, our suggestion is to start from a multi and interdisciplinary work resulting in these foundational questions: does a development path exist for the SIVE field? Is an <em class="EmphasisTypeItalic ">ad-hoc</em> theoretical approach necessary? Without going into the details of the epistemological crisis that is affecting the HCI field, we would try to avoid discussions on what is called in the HCI community <em class="EmphasisTypeItalic ">intermediate knowledge</em> [<span class="CitationRef"><a epub:type="biblioref" href="#CR72" role="doc-biblioref">72</a></span>] where positivist and constructivist perspectives are constantly clashing [<span class="CitationRef"><a epub:type="biblioref" href="#CR45" role="doc-biblioref">45</a></span>]. Examples of intermediate knowledge are all patterns/best practices proposed for certain aspects of the immersive experience.</p><div class="Para" id="Par106">There exist several classifications attempting to describe virtual spaces for sound and music purposes. The recent formulation in [<span class="CitationRef"><a epub:type="biblioref" href="#CR4" role="doc-biblioref">4</a></span>] distinguished three aspects:<div class="UnorderedList"><ul class="UnorderedListMarkBullet"><li><p class="Para" id="Par107">Immersive audio—the VE should provide the feeling of being surrounded by a world of sounds.</p></li><li><p class="Para" id="Par108">Interactive audio—the VE allows the user to influence the virtual world in some meaningful way.</p></li><li><p class="Para" id="Par109">Virtual audio—the virtual world must be dynamically simulated.</p></li></ul></div>
</div><p class="Para" id="Par110">They have already been extensively discussed in the previous sections and many of the existing taxonomies for VR [<span class="CitationRef"><a epub:type="biblioref" href="#CR95" role="doc-biblioref">95</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR134" role="doc-biblioref">134</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR157" role="doc-biblioref">157</a></span>] prioritizing the system (or simulation) or the user, not the close relationship with the listener. In this section, we propose an <strong class="EmphasisTypeBold ">audio-centered taxonomy</strong> that does not distinguish between user and system, listener and simulation. Our theoretical framework uses an egocentric audio perspective by emphasizing the situated, embodied, enactive dimensions of the listener’s experiences with their different actors involved. An emphasis on the entanglement between humans and technology assumes that the listener’s internal states are directly inaccessible to a non-intrusive and external technology, i.e., focused on exteroceptive sense [<span class="CitationRef"><a epub:type="biblioref" href="#CR134" role="doc-biblioref">134</a></span>]. Accordingly, we will motivate the selection of three dimensions able to describe a technological mediation in VR: <strong class="EmphasisTypeBold ">immersion</strong>, <strong class="EmphasisTypeBold ">coherence</strong>, and <strong class="EmphasisTypeBold ">entanglement</strong>. The qualitative description in this section leaves as a future challenge a quantification of the performative processes introduced here.</p><p class="Para" id="Par111">Referring to the autobiographical element introduced in the book preface, the first meeting of the two chapter authors at the ACM CHItaly 2011, the biennial conference of the Italian HCI community, has also a scientific meaning for the proposed taxonomy. The paper by Geronazzo et al. [<span class="CitationRef"><a epub:type="biblioref" href="#CR50" role="doc-biblioref">50</a></span>] was presented more than 10 years ago, as one of the first tasks of the first author’s doctoral program. He attempted to adapt the <em class="EmphasisTypeItalic ">virtuality continuum </em>of Milgram and Kishino [<span class="CitationRef"><a epub:type="biblioref" href="#CR95" role="doc-biblioref">95</a></span>] in the context of spatial audio personalization technologies for VR/AR. His main motivation was to overcome his difficulty in fitting the strong acoustic relationship (i.e., HRTF customization) between listener and technology into a taxonomy created for visual displays in 1994.</p><div class="Para" id="Par112">That paper proposes a characterization that uses a simplified two-dimensional parameter space defined in terms of the <em class="EmphasisTypeItalic ">degree of immersion</em> (DI) and <em class="EmphasisTypeItalic ">coordinate system deviation</em> (CSD) from the physical world. It is a simplification of Milgram’s three-dimension space, summarized in the following:<div class="UnorderedList"><ul class="UnorderedListMarkBullet"><li><p class="Para" id="Par113">Extent of World Knowledge (EWK): knowledge held by the system about virtual and physical worlds.</p></li><li><p class="Para" id="Par114">Reproduction Fidelity (RF)—virtual object rendering: quality of the stimuli presented by the system, in terms of multimodal congruency with their real counterpart.</p></li><li><p class="Para" id="Par115">Extent of Presence Metaphor (EPM)—subject sensations: this dimension takes into account the observer’s sense of presence.</p></li></ul></div>
</div><p class="Para" id="Par116">CSD matches EWK with the distinction that a low CSD means a high EWK: the system knows everything about the material world and can render the synthetic environment in a unified mixed world. From an ecological perspective, the system knows and dynamically fosters the overlap between real and virtual. On the other hand, EPM and RF are not entirely orthogonal and the definition of DI follows this idea: when a listener is surrounded by a real sound, all his/her body interacts with the acoustic waves propagating in the environment, i.e., a technology with high presence can monitor the whole listener’s embodiment and actions (high DI).</p><p class="Para" id="Par117">Recently Skarbez et al. [<span class="CitationRef"><a epub:type="biblioref" href="#CR134" role="doc-biblioref">134</a></span>] have proposed a revised version of Milgram’s virtuality <span id="ITerm54">continuum</span> introducing two distinctive elements. First, the consideration of only two instead of three Milgram’s dimensions similarly to [<span class="CitationRef"><a epub:type="biblioref" href="#CR50" role="doc-biblioref">50</a></span>]: Immersion and Extent of World Knowledge. In particular, Immersion is exactly based on the same idea as DI. Second, they introduced a discontinuity in the RF and EPM dimensions considering the absence of any display at the left side of the spectrum: the physical world without mediation is inherently different from the highest level of realism achievable through VR technologies that stimulate exteroceptive senses (i.e., sight, hearing, touch, smell, and taste). The latter consideration propagates to Immersion.</p><p class="Para" id="Par118">The rough taxonomy of Geronazzo <em class="EmphasisTypeItalic ">et. al.</em> missed the idea of coherence between simulation and human behavior, which is well identified as the third analytical dimension of Skarbez et al. [<span class="CitationRef"><a epub:type="biblioref" href="#CR134" role="doc-biblioref">134</a></span>]: <em class="EmphasisTypeItalic ">coherence</em>. It takes into account both plausibility and expectation of technological behaviors for the user in cognitive, social, and cultural terms. However, the three proposed dimensions cannot and do not claim to describe such a relationship between the user and the system as emphasized by the authors in their system-centered taxonomy. The work of Skarbez and colleagues is once again anchored to the distinction between user and system which generates several issues in framing the intra-actions of actors/factors in VR/AR sonic experiences.</p><p class="Para" id="Par119">To support the SIVE theoretical framework, we focus on purely VR only. This means that our discussion will not consider the CSD/EWK dimension assuming that there are no anchors to the physical world. However, since we are emphasizing the influence of human-real-world relationships on experience in VE and vice versa, we have decided not to make the world configurations explicit thus considering them as a whole with the listener. Extensions to mixed reality will be an object of future studies in a reviewed version of our theoretical framework.</p><div class="Para" id="Par120">Starting from the previously identified dimensions of Immersion [<span class="CitationRef"><a epub:type="biblioref" href="#CR50" role="doc-biblioref">50</a></span>] and Coherence [<span class="CitationRef"><a epub:type="biblioref" href="#CR134" role="doc-biblioref">134</a></span>]<strong class="EmphasisTypeBold ">, </strong>we suggest <strong class="EmphasisTypeBold ">three top-level categories </strong>that need to be addressed through interdisciplinary design work. A schematic representation can be found in Fig. <span class="InternalRef"><a href="#Fig5">1.5</a></span>.<figure class="Figure" id="Fig5"><div class="MediaObject" id="MO5"><img alt="" src="../images/478239_1_En_1_Chapter/478239_1_En_1_Fig5_HTML.png" style="width:20.28em"/></div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 1.5</span><p class="SimplePara">Three-dimensional taxonomy for SIVE, (a) Immersion, (b) Coherence, (c) Entanglement, and their relations in (d)</p></div></figcaption></figure>
</div><p class="Para" id="Par121"><strong class="EmphasisTypeBold ">Immersion: </strong><span id="ITerm55"/> the digital information related to the listener-digital twin relationship supporting an increasing number of actions in VEs. It measures the technological level and its enactive potential between listener and auditory digital twin.</p><p class="Para" id="Par122"><strong class="EmphasisTypeBold ">Coherence: </strong><span id="ITerm56"/> the digital information related to the digital-twin-VE relationship that allows the plausible rendering of an increasing number of behaviors in VEs. It measures the effectiveness of sonic interaction design in VEs.</p><p class="Para" id="Par123"><strong class="EmphasisTypeBold ">Entanglement: </strong><span id="ITerm57"/> represents the overall effectiveness of the actor-network and its agential cuts that are dynamically, individually, and adaptively created. It measures participation in the locus of agency and its consequent phenomenological description. The auditory digital twin actively proposes new relations favoring redefinitions in the agential cuts, i.e., the mutual transformative actions between listener and technology.</p><p class="Para" id="Par124">To support our proposed taxonomy for SIVE, we introduce a case study on a fictitious and purely theoretical artifact along the lines of <em class="EmphasisTypeItalic ">Flow</em> [<span class="CitationRef"><a epub:type="biblioref" href="#CR45" role="doc-biblioref">45</a></span>]. It allows us to decline the various facets of the framework in a flexible example.</p><p class="Para" id="Par125"><em class="EmphasisTypeItalic ">Spritz!</em><span id="ITerm58"/> is an interactive and immersive VR simulation supported by full-body tracking, stereoscopic vision, and headphone auralization. It is designed to address the <em class="EmphasisTypeItalic ">cocktail-party effect</em>. The human selective attention requires different contributions and levels of perception in supporting the ability to segregate signals-also referred to as auditory signal analysis [<span class="CitationRef"><a epub:type="biblioref" href="#CR15" role="doc-biblioref">15</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR20" role="doc-biblioref">20</a></span>]. When confronted with multiple simultaneous stimuli (speech or non-linguistic stimuli), it is necessary to segregate relevant auditory information from concurrent background sounds and to focus the attention on the source of interest. This action is related to the principles of auditory scene analysis that require a stream of auditory information filtered and grouped into many perceptually distinct and coherent auditory objects. In multi-talker situations, auditory object formation and selection together with attentional allocation contribute to defining a model of cocktail-party listening [<span class="CitationRef"><a epub:type="biblioref" href="#CR75" role="doc-biblioref">75</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR132" role="doc-biblioref">132</a></span>]. The design of <em class="EmphasisTypeItalic ">Spritz! </em>aims to give shape to an auditory digital twin able to detect listener intent, i.e., identify the relevance of a sound compared to other overlapping events. It can instantaneously determine the attentional balance within an auditory space. Its main goal is to promote the listener’s well-being through manipulations of the sound scene in a participatory way respecting the listener’s desires.</p><section class="Section2 RenderAsSection2" id="Sec11"><h3 class="Heading"><span class="HeadingNumber">1.4.1 </span>Immersion</h3><p class="Para" id="Par126">According to Murray [<span class="CitationRef"><a epub:type="biblioref" href="#CR98" role="doc-biblioref">98</a></span>], the term <em><strong class="EmphasisTypeBoldItalic "><span id="ITerm59">immersion</span>
</strong></em> comes from the physical experience of being immersed in water. In a psychologically immersive experience, one aims at experiencing the feeling of being surrounded by a medium that is a reality other than the physical one, able to capture our attention and all our senses. Therefore, it has an important element of continuity with our framework by identifying a mediating action of VR experiences. According to Slater and Wilbur [<span class="CitationRef"><a epub:type="biblioref" href="#CR137" role="doc-biblioref">137</a></span>], the term <strong class="EmphasisTypeBold ">immersion is tightly linked to the technology</strong>, the mediator, to elicit the sense of presence. Technological systems for immersive VR count several combinations of equipment and techniques, such as HMD, multimodal feedback, high frame rates, and large tracking areas. Such a heterogeneous arsenal is a complex system of functional elements that have an immediate impact on the listener’s experience. Initially, technical specifications were reasonably identified as the main constraints for a VR experience. However, other elements were considered with a large-scale diffusion of VR technologies. The design of VEs became critical in those details that ensure a plurality of actions with virtual objects, the surrounding virtual world, and their representations. As discussed in [<span class="CitationRef"><a epub:type="biblioref" href="#CR30" role="doc-biblioref">30</a></span>], the effects of all these components are highly interconnected with each other. Moreover, the absence or misuse of any of them can produce immediate disruptions in the sense of presence or <span id="ITerm60">cybersickness</span> [<span class="CitationRef"><a epub:type="biblioref" href="#CR33" role="doc-biblioref">33</a></span>], such as low headset quality [<span class="CitationRef"><a epub:type="biblioref" href="#CR16" role="doc-biblioref">16</a></span>] or unfiltered noise caused by sound sources external to the VR setup [<span class="CitationRef"><a epub:type="biblioref" href="#CR136" role="doc-biblioref">136</a></span>].</p><p class="Para" id="Par127">The strong connection between immersion and equipment means that different VR solutions hold an intrinsic level of immersion regardless of the actual applications performed with them [<span class="CitationRef"><a epub:type="biblioref" href="#CR120" role="doc-biblioref">120</a></span>]. This is evident when considering basic audio quality vs. quality of the listening experience. For instance, considering projected screens offers designers of VEs the opportunity to combine real and virtual elements in the tracked area (Chap. <span class="ExternalRef"><a href="478239_1_En_13_Chapter.xhtml"><span class="RefSource">13</span></a></span> offers an interesting reflection on artistic performances mediated by VR/AR technologies). However, the overall sense of presence experienced by the listener depends on the specific combination of the HW/<span id="ITerm61">SW</span> setup. Such setups support a certain type of action within the VE. The <strong class="EmphasisTypeBold ">Immersion “I” </strong>dimension takes into account these features as the starting point of an enactive potential for the auditory digital twin. Such a potential intrinsically limits the development and creation of new actions.</p><p class="Para" id="Par128">Furthermore, the enactive egocentric perspective of Sect. <span class="InternalRef"><a href="#Sec4">1.3.1</a></span> provides a solid theoretical framework for considering the importance of ecologically valid auditory information in eliciting a sense of presence in a VR-mediated experience. First of all, it should be mentioned that there is a lack of research related to the effects of interactive sound on the sense of body ownership and agency (refer to the discussion in Chap. <span class="ExternalRef"><a href="478239_1_En_2_Chapter.xhtml"><span class="RefSource">2</span></a></span>). The vast majority of studies addressing presence from an auditory perspective focus on place <span id="ITerm62">illusion</span> and spatial attributes. This should not come as a surprise, since many of these binaural attributes are perceived by applying sensory-motor contingencies and embodied multisensory integrations. A simple example in spatial audio technologies is the importance of head movements data that are acquired by three degree-of-freedom head-<span id="ITerm63">trackers</span>, allowing listeners to exploit binaural cues for resolving the so-called <em class="EmphasisTypeItalic ">front-back <span id="ITerm64">confusion</span>
</em> [<span class="CitationRef"><a epub:type="biblioref" href="#CR22" role="doc-biblioref">22</a></span>]. However, computational models for binaural cues are usually parameterized by the head radius or circumference, or ears position [<span class="CitationRef"><a epub:type="biblioref" href="#CR52" role="doc-biblioref">52</a></span>]. This example suggests that synchronization and plausible interactive variations, i.e., occurring in reaction to the digital twin’s gestures in coherence with sensorimotor contingencies, can positively influence the sense of agency. In addition, other studies demonstrate how the <strong class="EmphasisTypeBold ">sound of action</strong> and an active exploration can support haptic sensations and vice versa in a co-located and simultaneous manner. For instance, Chap. <span class="ExternalRef"><a href="478239_1_En_12_Chapter.xhtml"><span class="RefSource">12</span></a></span> analyzes the impact of sound in an audio-tactile identification of everyday materials from a bouncing ball.</p><p class="Para" id="Par129">Regarding spatial hearing, there is a huge differentiation in accuracy between more (experienced) and less (naive) reliable listeners [<span class="CitationRef"><a epub:type="biblioref" href="#CR3" role="doc-biblioref">3</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR51" role="doc-biblioref">51</a></span>]. More generally, the distinction between categories of <span id="ITerm65">listeners</span> is still challenging and is made based on several factors such as multisensory calibration and integration (see Chap. <span class="ExternalRef"><a href="478239_1_En_12_Chapter.xhtml"><span class="RefSource">12</span></a></span> for audio-haptics), familiarity with immersive/spatial audio technologies, musical background [<span class="CitationRef"><a epub:type="biblioref" href="#CR152" role="doc-biblioref">152</a></span>], or audio mixing experience (as in Chap. <span class="ExternalRef"><a href="478239_1_En_9_Chapter.xhtml"><span class="RefSource">9</span></a></span>), etc. Both acoustic (i.e., acoustic transformations of the body) and non-acoustic (i.e., everything else) factors are highly individual and depend on the relationship between the listener and the real-world which is mediated by technology in a general sense (not only in the digital domain, e.g., games, musical instruments, etc.).</p><p class="Para" id="Par130">All <strong class="EmphasisTypeBold ">objectifiable information regarding the listener</strong> are known configurations. For example, bottom-up approaches for modeling psychophysical phenomena of spatial hearing and multisensory integration fall into this category. Such knowledge has to be integrated into the immersive system, explicitly contributing to the actor-network managed by the digital twin.</p><p class="Para" id="Par131">Coming back to our <em class="EmphasisTypeItalic ">Spritz! </em>simulation, the level of <strong class="EmphasisTypeBold ">I</strong> is expected to be high due to state-of-the-art technological components. The digital twin can recognize and manage several full-body skeletal configurations as well as near-field acoustics algorithms that take into account the acoustic coupling of the main joints such as the head and shoulders. This last aspect is usually largely underestimated in virtual acoustics systems [<span class="CitationRef"><a epub:type="biblioref" href="#CR17" role="doc-biblioref">17</a></span>]. The customization based on anthropometry allows the digital twin to guide the acoustic rendering of movements considering head tilt and torso shadowing in real-time. Furthermore, binaural and spectral cues might be personalized and weighted according to the listener’s level of uncertainty, allowing the digital twin to predict which sound sources are most likely to be segregated based on an egocentric direction-of-arrival perspective.</p><p class="Para" id="Par132">The contribution of the <strong class="EmphasisTypeBold ">I</strong> dimension can be summarized as follow: <strong class="EmphasisTypeBold ">I</strong> is the digital information related to the listener-digital twin relationship limited by a specific technological setup. The support of an increasing number of actions in VEs is a consequence of technological improvements (both HW/SW) and/or an increasing objectification of the listener’s configurations. Considering the idea of immersive potential of Chap. <span class="ExternalRef"><a href="478239_1_En_11_Chapter.xhtml"><span class="RefSource">11</span></a></span>, limitations in enaction determine which changes are significant after technological manipulation. The level of reconfigurability within the digital twin accounts for the constant dialogue with the listener to explore her state and tendency to immersion in every moment of the experience (see also Sect. <span class="InternalRef"><a href="#Sec13">1.4.3</a></span>).</p></section><section class="Section2 RenderAsSection2" id="Sec12"><h3 class="Heading"><span class="HeadingNumber">1.4.2 </span>Coherence</h3><p class="Para" id="Par133">The VR simulation must be able to make the digital twin freely interact with the VE, eliciting a plausible experience for the listener who is always aware of the mediated nature of the experience. In other words, the interaction design must support functionally and plausible actions, the ‘doing’ in [<span class="CitationRef"><a epub:type="biblioref" href="#CR43" role="doc-biblioref">43</a></span>]. This means that possible configurations of the technical setup and the listener (the objectification in the digital-twin, see Sect. <span class="InternalRef"><a href="#Sec11">1.4.1</a></span>) constitute the enactive potential of immersion and must be balanced within the sonic interactions.</p><p class="Para" id="Par134">In this section, we focus on the <em><strong class="EmphasisTypeBoldItalic "><span id="ITerm66">coherence</span>
</strong></em> of the digital-twin/environment relationship. On the other hand, Sect. <span class="InternalRef"><a href="#Sec13">1.4.3</a></span> provides an interpretation of the dialogue with the <em><strong class="EmphasisTypeBoldItalic ">immersion </strong></em>dimension.</p><p class="Para" id="Par135">VE simulations can create fictional worlds, exploiting opportunities for both naturalistic and magical <span id="ITerm67">interactions</span> [<span class="CitationRef"><a epub:type="biblioref" href="#CR13" role="doc-biblioref">13</a></span>]. Designers can experiment with defining rules that only apply in the virtual domain, such as scale, perspective, and time. The philosophical discussion of the dualism “Doing vs. Being” in [<span class="CitationRef"><a epub:type="biblioref" href="#CR4" role="doc-biblioref">4</a></span>] provides interesting insights into our egocentric auditory perspective: simulation can have different levels of interactivity suggesting different action spaces for the digital twin in the virtual worlds.</p><p class="Para" id="Par136">Interacting with the VE, avatar included, consists of <strong class="EmphasisTypeBold ">altering the states of 3D elements</strong> that have been created at different levels of proximity: the virtual body (i.e., avatar), the foreground (i.e., peripersonal object manipulation space), and in the background (i.e., extra-personal virtual world space). Existing researches on <span id="ITerm68">3D interaction</span> focuses on the spatial aspects of the following main categories: selection, manipulation, navigation, and application control (the latter involving menus and other VE configuration widgets). Selection techniques allow users to indicate an object or a group of objects. According to the classification of Bowman et al. [<span class="CitationRef"><a epub:type="biblioref" href="#CR14" role="doc-biblioref">14</a></span>], one can consider selection techniques based on object indication (occlusion, object touch, pointing, indirect selection), activation method (event, gesture, voice command), and feedback type (text, acoustic, visual, force/tactile). Manipulation techniques allow the digital twin to modify all virtual objects configurations that are made accessible to it: e.g., the spatial transformation of objects, i.e., roto-translation and scaling, surface properties such as material texture and acoustic properties, or 3D shape and structure manipulations. For the variety of interaction metaphors for selection, we refer to a recent review in [<span class="CitationRef"><a epub:type="biblioref" href="#CR92" role="doc-biblioref">92</a></span>]. Finally, navigation techniques allow digital twins to move within the VE to explore areas and virtual worlds. Typical movements include <span id="ITerm69">walking</span> and virtual transportation, including flight experiences. In particular, walking is fundamental to humans, and supporting natural locomotion is not always feasible on a limited tracked space. Accordingly, there are other interaction metaphors such as walk-in-place [<span class="CitationRef"><a epub:type="biblioref" href="#CR42" role="doc-biblioref">42</a></span>], <span id="ITerm70">teleportation</span>, or semi-automatic movements between control points [<span class="CitationRef"><a epub:type="biblioref" href="#CR61" role="doc-biblioref">61</a></span>]. It is worthwhile to mention the self-motion illusions. In circular vection [<span class="CitationRef"><a epub:type="biblioref" href="#CR116" role="doc-biblioref">116</a></span>], moving sounds surrounding the listeners facilitate the perception of being in motion when in fact they are not. For spatial design considerations in sonic interactions, Chap. <span class="ExternalRef"><a href="478239_1_En_6_Chapter.xhtml"><span class="RefSource">6</span></a></span> provides a comprehensive analysis and a typology of VR interactive audio systems.</p><p class="Para" id="Par137">These configurations must be plausible and the digital twin should support a dynamic transition from one to another. This is crucial to avoid irreparable breaks in presence. Therefore, <strong class="EmphasisTypeBold ">coherence “C” </strong>describes the degrees of freedom introduced by the sonic interaction design in VEs based on the active dialogue between the digital-twin and the VE, established experience after experience.</p><p class="Para" id="Par138">In this section, we are particularly interested in the plausibility <span id="ITerm71">illusion</span> determined by the overall credibility of a VE concerning subjective expectations. It is not only a coherence between external events not directly caused by listeners but an objective feature of the VE [<span class="CitationRef"><a epub:type="biblioref" href="#CR134" role="doc-biblioref">134</a></span>]. Its reconfigurability includes an <strong class="EmphasisTypeBold ">internal logical coherence and a behavioral consistency</strong> considering prior knowledge. Sound conveys ecological information relevant to the expectation toward VE behaviors compared to the listener’s everyday experience: embodied, and situated in a socio-cultural context. The environment configurations (avatars and virtual worlds) intertwine with the known listener configurations held in the digital twin. Once again, the digital twin has a central and active role following an egocentric audio perspective (see Fig. <span class="InternalRef"><a href="#Fig4">1.4</a></span> for this foundational idea). Dimension <strong class="EmphasisTypeBold ">C</strong> advocates a top-down approach to interactions, constituted of cognitive and socio-cultural influences based on listener real life.</p><p class="Para" id="Par139">Moreover, coherence does not presuppose physical realism. It fosters interactions in coherent virtual magic worlds. The dynamic dialogue between VE and digital-twin makes it possible. For example, let’s consider a cartoon world where simplified descriptions of sound phenomena exaggerate certain features [<span class="CitationRef"><a epub:type="biblioref" href="#CR118" role="doc-biblioref">118</a></span>]. It may be plausible as long as it conveys relevant ecological information. Audio procedural models are based on simplifications in properties and behavior of a the corresponding real object, i.e., simplified <span id="ITerm72">configurations</span>. Such parameterization can be informed by auditory perception and cognition maintaining ecological validity of a fictional sonic world while reinforcing the listener’s sense of agency. Digital information regarding the relationship between the digital twin and VE allows the creation of an increasing number of plausible behaviors in VR.</p><p class="Para" id="Par140">Considering once again the distinction among avatar, peri- and extra-personal spaces, neurophysiological research on body ownership and multisensory <span id="ITerm73">integration</span> suggests the existence of a fluid boundary in the <strong class="EmphasisTypeBold ">perceived space by subjects</strong> [<span class="CitationRef"><a epub:type="biblioref" href="#CR60" role="doc-biblioref">60</a></span>]. It is worth noticing that the neuronal activity sensitive to the appearance of stimuli within the personal space is multisensory in nature and involves neurons located in the frontoparietal area. In this area, neuronal activity is related to action preplanning particularly for reacting to potential threats [<span class="CitationRef"><a epub:type="biblioref" href="#CR130" role="doc-biblioref">130</a></span>] and elicits defensive movements when stimulated [<span class="CitationRef"><a epub:type="biblioref" href="#CR32" role="doc-biblioref">32</a></span>]; these multimodal neurons combine somatosensory with body position information [<span class="CitationRef"><a epub:type="biblioref" href="#CR58" role="doc-biblioref">58</a></span>]. Bufacchi and Iannetti [<span class="CitationRef"><a epub:type="biblioref" href="#CR24" role="doc-biblioref">24</a></span>] suggested that the personal <span id="ITerm74">space</span> should be described as a series of action fields that spatially and dynamically define possible responses and create contact-prediction functions with objects. Such fields may vary in location and size, depending on the body interaction within the environment and its actual and predicted location. Space is also modulated in response to external stimuli and internal states of the subject, defining a relationship between listener, environment, and tools [<span class="CitationRef"><a epub:type="biblioref" href="#CR119" role="doc-biblioref">119</a></span>].</p><p class="Para" id="Par141">Of particular interest for our framework are modulations due to the <strong class="EmphasisTypeBold "><span id="ITerm75">proxemics</span>
</strong>. The term was introduced by Hall [<span class="CitationRef"><a epub:type="biblioref" href="#CR63" role="doc-biblioref">63</a></span>] and concerns implicit social rules of interpersonal distance among people conveying different social meanings. The cooperation in a socially shared interpersonal space [<span class="CitationRef"><a epub:type="biblioref" href="#CR144" role="doc-biblioref">144</a></span>] requires to support the transition from individual to collaborative <span id="ITerm76">spaces</span> [<span class="CitationRef"><a epub:type="biblioref" href="#CR142" role="doc-biblioref">142</a></span>]. In Chap. <span class="ExternalRef"><a href="478239_1_En_8_Chapter.xhtml"><span class="RefSource">8</span></a></span>, the design of sound intensity (or sound attenuation) as a function of the proximity from a sound source is addressed. Different configurations of personal and public spaces were tested in a shared VE for collaborative music composition. Interestingly, rigid boundaries in the transition between spaces forced listeners to take a <strong class="EmphasisTypeBold ">social distance</strong> and isolate with a negative impact on the collaborative aspects of the composition process. Therefore, the separation between public and personal space should be fluid rather than rigid. The VE should be configurable in the social aspects that emerge from the strong interconnection between configurations made available to the digital twin, increasing the fluidity and better supporting collaboration in <span id="ITerm77">shared</span> experiences.</p><p class="Para" id="Par142">In <em class="EmphasisTypeItalic ">Spritz!</em>, we should identify the VE’s abilities in shaping the simulation within the digital twin. First, <em class="EmphasisTypeItalic ">Spritz!</em> has multiple configurations accounting for different strategies of the level of audio details. The radial distance with an egocentric reference can drive the dynamic definition of three partially overlapping levels of detail associated with proximity profiles: avatar, personal and public. The avatar’s movement sounds are rendered through procedural approaches with individualized configurations based on listener acoustics; in the personal space, <em class="EmphasisTypeItalic ">Spritz!</em> can manipulate sound behavior with simplified models taking into account security and privacy levels required by the situated and embodied states of the digital twin. Finally, sounds in the public space can be clustered, grouped, or attenuated by implementing plausible statistical behavior, e.g., using audio impostor replacement such as audio samples.</p><p class="Para" id="Par143">The <em class="EmphasisTypeItalic ">Spritz! </em>environment should facilitate resolutions of the cocktail-party problem in crowded situations. Accordingly, it should be able to apply noise suppression of negligible information in the public space or vice versa to operate audio enhancements supporting attentive focus. This dynamic connection between VE and digital twin should be able to maintain <em class="EmphasisTypeItalic ">coherence </em>in the induced behaviors, supporting the plausibility of actions while bending the space around the listener.</p><p class="Para" id="Par144">A meaningful manipulation of virtual spaces is crucial and creative. Since SIVE naturally includes researches in music composition, a VE must foster the development of individual or collaborative creative ideas through dynamic control of its configurations within and by the digital twin. In particular, results in Chap. <span class="ExternalRef"><a href="478239_1_En_8_Chapter.xhtml"><span class="RefSource">8</span></a></span> support VE spatial design as the creation of  “magical” exploratory opportunities, adding original dynamics to collaborative work in VEs. The digital twin has a pivotal role in such space modulations that allow tracing boundaries performatively and eliciting internal emotional states following the listener/composer’s expectations.</p></section><section class="Section2 RenderAsSection2" id="Sec13"><h3 class="Heading"><span class="HeadingNumber">1.4.3 </span>Entanglement</h3><p class="Para" id="Par145">The listener’s susceptibility to immersive VE experiences is usually determined by administering questionnaires [<span class="CitationRef"><a epub:type="biblioref" href="#CR155" role="doc-biblioref">155</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR156" role="doc-biblioref">156</a></span>]. The experimenters’ aim is usually to perform a screening test to distinguish who can and will be able to easily immerse in a VR-mediated situation. Furthermore, this separation is assumed to remain constant throughout a short-enough experiment. However, the immersive <span id="ITerm78">tendency</span> can change over time due to training, learning, experience, mood changes and personality, etc. (see Chap. <span class="ExternalRef"><a href="478239_1_En_11_Chapter.xhtml"><span class="RefSource">11</span></a></span> for further details). For such reasons, common recommendations for VR experiments suggest conducting single experimental sessions. However, studying the impact of the aforementioned dynamic changes opens to the third and last dimension of our taxonomy: <em><strong class="EmphasisTypeBoldItalic "><span id="ITerm79">entanglement</span>
</strong></em>, which is the knowledge extraction from the evolution of an actor-network able to reveal multiple facets of the egocentric experience in time, space, and intra-actions.</p><p class="Para" id="Par146">The first step requires describing the available configurations. Starting from the idea of immersive tendency, VR simulation would benefit from the <strong class="EmphasisTypeBold ">knowledge of the listener’s susceptibility</strong> toward configurations of setup and environment to modify or avoid non-significant experiences, e.g., getting a break in illusion. In other words, (quantifiable) listener configurations must be defined, discovered, and actively explored by the digital twin. For example, the way sound samples are engineered is very interesting here. A sliding friction sample, e.g., squeaking, rubbing, etc., requires a large amount of data and randomization techniques to avoid repetition. Sounds should be consistent with the listener’s expectations in response to complex and continuous motor actions. For this reason, procedural audio approaches can tightly connect the sound to complex and continuous motor actions.</p><p class="Para" id="Par147">The <strong class="EmphasisTypeBold ">Entanglement</strong> dimension (“<strong class="EmphasisTypeBold ">E</strong>” ) aims to provide a phenomenological characterization of actors’ evolution and activities based on their performativity and participation in a locus of agency. We realize the high complexity of such a descriptive and formal process, but we believe that an attempt in capturing the <strong class="EmphasisTypeBold ">transformative potential of VR</strong> in mediated experiences is worthwhile to be conducted for the SIVE discipline. Of great importance here is the idea of <strong class="EmphasisTypeBold "><span id="ITerm80">monad</span>
</strong> by sociologists Tarde and Latour [<span class="CitationRef"><a epub:type="biblioref" href="#CR84" role="doc-biblioref">84</a></span>, <span class="CitationRef"><a epub:type="biblioref" href="#CR143" role="doc-biblioref">143</a></span>]: <em class="EmphasisTypeItalic ">“A monad is not a part of a whole, but a point of view on all the entities taken severally and not as a totality”.</em>One can consider a monad as a relational perspective of each actor, shifting the emphasis from aggregation of the whole to movement between different points of view. The main purpose of any perspective is the structural analysis of the network and its configurations and, at a later stage, to derive knowledge and understanding of its dynamics. The inherently egocentric local perspective of the locus of agency, i.e., digital twin, is again emphasized as opposed to a global view. Egocentric networks built around specific nodes such as the listener configurations can support the exploration of intra-activated dynamics. Configurations and links can be discovered and/or modified during different mediated experiences.</p><p class="Para" id="Par148">The <strong class="EmphasisTypeBold ">collaboration among actors is vital in integrating different points of view</strong>, creating opportunities for meaningful experiences. In shared VEs (Chap. <span class="ExternalRef"><a href="478239_1_En_8_Chapter.xhtml"><span class="RefSource">8</span></a></span>), listeners are co-present with other human participants interacting in an interpersonal way. Research interests of computing-supported cooperative work can provide interesting insights into prioritizing collaboration [<span class="CitationRef"><a epub:type="biblioref" href="#CR99" role="doc-biblioref">99</a></span>]. The choice of collaborative models fostering the design of active VEs for meaningful and creative experiences is of particular relevance to entangled SIVE.</p><p class="Para" id="Par149">Intentionality and gesture support can be achieved through continuous network reconfiguration. Identifying common goals through inter-actor communication are fundamental requirements to increase the digital-twin enactive <span id="ITerm81">potential</span>. We argue that this area of research is absolutely new for SIVE, especially in these collaborative aspects. Many fundamental and critical questions for SIVE are waiting to be answered.</p><p class="Para" id="Par150">Digital transformation promotes ubiquitous and <span id="ITerm82">pervasive</span> interconnected data sets with the opportunity to offer new ways of navigating and extracting knowledge. Dork et al. [<span class="CitationRef"><a epub:type="biblioref" href="#CR37" role="doc-biblioref">37</a></span>] explored the visualization of relational information spaces, incorporating both the individual and the whole in a monadic perspective. The authors’ goal was to exploit the rich semantic connections to design new exploration methods for interconnected elements. There is an increasing interest in more exploratory forms of information retrieval without specific needs/constraints, sustained by the <strong class="EmphasisTypeBold ">desire to learn, play and discover</strong> openly [<span class="CitationRef"><a epub:type="biblioref" href="#CR91" role="doc-biblioref">91</a></span>]. In analogy with these practices, the digital twin should curiously move between nodes, configurations, and connections experimenting and manipulating the actor-network for sense-making. To encourage surprising discoveries and interest within experiences, the digital twin should offer unconventional and appealing views with the agency.</p><p class="Para" id="Par151">The auditory digital twin actively proposes new relationships and encourages agential cuts under the mutual transformative action between listener and technology. In the monadic perspective of the digital twin, the distinctive qualities of each actor within a VE should emerge in each situated experience. Differentiation among configurations is not an a priori actor property but it is identified by its uniqueness in the network. Each actor imprints its particular identity on an ever-changing relational world. In other words, the digital twin is looking for differences in each actor by considering different monadic perspectives. VR simulations allow us to take the point of view of each element thanks to a shared virtual world knowledge.</p><p class="Para" id="Par152">In the area of AI <span id="ITerm83">agents</span>, i.e., non-human entities capable of interacting with ecological behaviors [<span class="CitationRef"><a epub:type="biblioref" href="#CR109" role="doc-biblioref">109</a></span>], intelligent algorithms would have the predictive potential on the listener’s action program. Their ability in monitoring and predicting listeners’ behavioral responses could enable the digital twin to determine listeners’ expectations and cognitive and psychological capabilities [<span class="CitationRef"><a epub:type="biblioref" href="#CR25" role="doc-biblioref">25</a></span>]. Moreover, AI algorithms could propose exploration paths to the listener within VEs. Therefore, the capabilities of safely navigating through temporary, transient, and overlapping configurations are definitely complimentary to their predictive power.</p><p class="Para" id="Par153">In line with the emerging research area called <strong class="EmphasisTypeBold ">immersive <span id="ITerm84">analytics</span>, </strong>humans and AI can support each other in decision-making based on the navigation in shared thinking spaces [<span class="CitationRef"><a epub:type="biblioref" href="#CR133" role="doc-biblioref">133</a></span>]. Meetings between the listener and her digital twin can take place in a virtual meta-environment where configurations and connections of an experience can be a posteriori analyzed, collaboratively. The unique personal supervision of the AI algorithms implemented in the digital twin could reflect the listener’s traits and interests. Understanding the listener’s preferences and assessing their impact on the predictive performance of AI algorithms can help to propose adaptive and customizable systems with a certain level of memory of past VR-mediated experiences [<span class="CitationRef"><a epub:type="biblioref" href="#CR103" role="doc-biblioref">103</a></span>].</p><p class="Para" id="Par154">Finally, how can we measure the overall effectiveness of an actor-network and its agential cuts that the digital twin dynamically, individually, and adaptively creates? This question corresponds to Latour et al.’s challenge to take into account long-term features, indicative of a systemic order that might be learned navigating overlapping perspectives (monads) [<span class="CitationRef"><a epub:type="biblioref" href="#CR84" role="doc-biblioref">84</a></span>]. Such an emphasis on navigation gives a unique role to <strong class="EmphasisTypeBold ">movement/exploration </strong><span id="ITerm85">as</span> a way of experiencing relationships and differences between configurations. Therefore, we suggest that the digital twin should navigate along with different and novel perspectives for sense-making. The dynamic relational quality of each actor’s unique position in network space, i.e., agential cuts, reflects the exploration potential shaping and creating meaning for the listener.</p><p class="Para" id="Par155">We argue that the VR-mediated experience is never solitary, considering both human and non-human actors. Any actor cooperates within a shared VE, e.g., to perform a musical performance (Chap. <span class="ExternalRef"><a href="478239_1_En_13_Chapter.xhtml"><span class="RefSource">13</span></a></span>) or a spatialized audio mixing (Chap. <span class="ExternalRef"><a href="478239_1_En_9_Chapter.xhtml"><span class="RefSource">9</span></a></span>). Collaboration takes place on a common task, which has a huge impact on the intra-action dynamics. In addition to the exploratory movements, technological transparency introduced in Sect. <span class="InternalRef"><a href="#Sec3">1.3</a></span> is a key factor influencing “E” measures. In analogy with the sense of presence, <strong class="EmphasisTypeBold ">co-<span id="ITerm86">presence</span>
</strong> [<span class="CitationRef"><a epub:type="biblioref" href="#CR26" role="doc-biblioref">26</a></span>], i.e., the feeling of sharing a VE with others, has been shown to strongly depend on avatar appearance and its realism, as well as on the cooperation level in task completion [<span class="CitationRef"><a epub:type="biblioref" href="#CR111" role="doc-biblioref">111</a></span>]. Another aspect worth mentioning here is the <strong class="EmphasisTypeBold "><span id="ITerm87">awareness</span>
</strong> [<span class="CitationRef"><a epub:type="biblioref" href="#CR7" role="doc-biblioref">7</a></span>] which is the action understanding of other actors, especially with non-human agents. This latter concept strongly relates to trustworthy AI issues and explainable AI [<span class="CitationRef"><a epub:type="biblioref" href="#CR70" role="doc-biblioref">70</a></span>]<span id="ITerm88"/>.</p><p class="Para" id="Par156">A further “E” measure in SIVE can be inspired by the River and MacTavish’s framework [<span class="CitationRef"><a epub:type="biblioref" href="#CR117" role="doc-biblioref">117</a></span>]. They proposed to generate low-level prototypes of an artifact from simplified attributes. The more extreme the change in such attributes, the more likely the change will be to provoke and reveal hidden assumptions in the design process. In our taxonomy, we call it generative potential in explorative movements and network changes, and technological transparency.</p><p class="Para" id="Par157">The final example in our fictitious case study <em class="EmphasisTypeItalic ">Spritz!</em> considers the meaningful prediction of the listener’s intentionality and the understanding of any sources of interest, e.g., avatar’s gestures or other avatars’ action. <em class="EmphasisTypeItalic ">Spritz! </em>should be able to support attentional focus. A virtual ray/cone pointer projected by the avatar through the VE or a virtual cursor/hand mapped to the listener’s body movements might facilitate the selection of points of interest. Gesture analysis could provide <em class="EmphasisTypeItalic ">Spritz!</em> relevant information for a semi-automatic focus support. This scenario opens to the experimentation and development of “magic” interactions of virtual superhuman hearing tools such as a dual audio beamformer guided by the avatar’s body [<span class="CitationRef"><a epub:type="biblioref" href="#CR52" role="doc-biblioref">52</a></span>]. <em class="EmphasisTypeItalic ">Spritz!</em> should be free to propose novel ways of interaction and exploration within VEs. This dynamic dialogue can be considered a form of <strong class="EmphasisTypeBold ">virtual <span id="ITerm89">provotyping</span>
</strong> that has to guarantee <em class="EmphasisTypeItalic ">coherence </em>with all available sensorimotor contingencies, having a positive effect on the listener’s sense of agency in any proposed behavior.</p></section></section><section class="Section1 RenderAsSection1" id="Sec14"><h2 class="Heading"><span class="HeadingNumber">1.5 </span>Conclusion</h2><p class="Para" id="Par158">This chapter aims at emphasizing how the SIVE book was born and developed in a constantly evolving situation in the field of human-computer interaction. We invite the reader to explore all its chapters with this shared and dynamic tension that we, as editors, have tried to formalize in what we have called the egocentric perspective of the auditory digital twin. The co-transformation of man and technology seems to us a central theme that will surely help us to enter the 4<span class="InlineEquation" id="IEq2"><img alt="$$^{th}$$" src="../images/478239_1_En_1_Chapter/478239_1_En_1_Chapter_TeX_IEq2.png" style="width:0.94em"/></span> HCI wave, consciously.</p><p class="Para" id="Par159">The proposed taxonomy focuses on action, behavior, and sense-making because we believe it is a meaningful way for authentic auditory experiences in VR. In particular, the last aspect of sense-making turns out to be the most challenging. The idea of diffraction and exploration of differences and discoveries requires novel ways of scientific investigation in SIVE. The most crucial aspect might be the level of personalization that future technologies will require to acquire from the listeners. New paradigms for artificial and immersive interaction between humans and VE will have to be proposed. The attribution of agency to a digital twin is a network effect that will have relevant ethical implications, as well as complexity in its analysis.</p><p class="Para" id="Par160">How much would the listener trust her digital twin? Its intermediary role, sometimes provocative, in search of differences can elicit strong reactions in the listeners. Will the listener accept and share this perspective? The affective information strongly links sound to meaning [<span class="CitationRef"><a epub:type="biblioref" href="#CR138" role="doc-biblioref">138</a></span>], creating empathy between listener and her digital twin. This aspect will be carefully considered for its ethical implications.</p><p class="Para" id="Par161">How can one quantify and classify the various actor networks in the proposed three dimensions? Surely, this is an open challenge of this first proposed theoretical framework for SIVE. Visualizing and representing transitions and agential cuts are relevant issues toward an objective description of any mediation phenomenon. Creating multiple ontologies in “magical” interaction metaphors allows to transcend reality and immerse into unique experiences within VEs. Since VR is not yet able to fully replicate natural reality and may not be able to do so, its current features actually allow listeners to do and be things that are impossible in the real world. This is the very essence of knowledge diffraction: the digital twin should explore such differences that are impossible to test in the physical world, extracting meaning for the listener. Of particular interest here, the ideas of superhuman powers and virtual prototyping [<span class="CitationRef"><a epub:type="biblioref" href="#CR52" role="doc-biblioref">52</a></span>] reflect human desire to increase her capabilities. They are receiving increasing attention thanks to the post-humanism and human enhancement manifestos [<span class="CitationRef"><a epub:type="biblioref" href="#CR97" role="doc-biblioref">97</a></span>]. Following this line of thought, Sadeghian et al. [<span class="CitationRef"><a epub:type="biblioref" href="#CR121" role="doc-biblioref">121</a></span>] proposed to VR designers to explore new forms of interaction without necessarily imitating the physical world. VR’s limitations in creating realistic interactions are replaced by a focus on experiences that are impossible to have in the real world, such as superhuman powers of flying, X-ray vision, shape-shifting, super memory, etc. Limitations obviously occurred while differentiating VEs before confusion invades the listener. Indeed, a balance in ecological and familiar stimulation should guide the creation of a “safety net” or “comfort zone” for the listener—the digital twin’s exploration of agonistic and provocative knowledge opportunities without drawbacks.</p><div class="Para" id="Par162">This chapter aims to shape the SIVE research field, <strong class="EmphasisTypeBold ">sonic interactions in VEs</strong>, that is now ready to welcome wide-ranging reflections on what might be called <blockquote class="BlockQuote"><p class="Para"> <strong class="EmphasisTypeBold ">sonic intra-actions in VEs</strong>. </p></blockquote>
</div></section><div class="License LicenseSubType-cc-by"><a href="https://creativecommons.org/licenses/by/4.0"><img alt="Creative Commons" src="../css/cc-by.png"/></a><p class="SimplePara"><strong class="EmphasisTypeBold ">Open Access</strong> This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (<span class="ExternalRef"><a href="http://creativecommons.org/licenses/by/4.0/"><span class="RefSource">http://​creativecommons.​org/​licenses/​by/​4.​0/​</span></a></span>), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made.</p><p class="SimplePara">The images or other third party material in this chapter are included in the chapter's Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter's Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</p></div><aside aria-labelledby="Bib1Heading" class="Bibliography" id="Bib1"><div epub:type="bibliography" role="doc-bibliography"><div class="Heading" id="Bib1Heading">References</div><ol class="BibliographyWrapper"><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">1.</div><div class="CitationContent" id="CR1">Adavanne, S., Politis, A., Nikunen, J., Virtanen, T.: Sound Event Localization and Detection of Overlapping Sources Using Convolutional Recurrent Neural Networks. IEEE Journal of Selected Topics in Signal Processing <strong class="EmphasisTypeBold ">13</strong>, 34-48 (2019).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">2.</div><div class="CitationContent" id="CR2">Alletto, S., Serra, G., Calderara, S., Cucchiara, R.: Understanding social relationships in egocentric vision. en. Pattern Recognition <strong class="EmphasisTypeBold ">48</strong>, 4082-4096 (2015).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">3.</div><div class="CitationContent" id="CR3">Andéol, G., Simpson, B. D.: Editorial: How, and Why, Does Spatial-Hearing Ability Differ among Listeners? What is the Role of Learning and Multisensory Interactions? Frontiers in Neuroscience <strong class="EmphasisTypeBold ">10</strong> (2016).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">4.</div><div class="CitationContent" id="CR4">Atherton, J., Wang, G.: Doing vs. Being: A philosophy of design for artful VR. Journal of New Music Research <strong class="EmphasisTypeBold ">49</strong>, 35-59 (2020).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">5.</div><div class="CitationContent" id="CR5">Aydin, C., González Woge, M., Verbeek, P.-P.: Technological Environmentality: Conceptualizing Technology as a Mediating Milieu. en. Philosophy &amp; Technology <strong class="EmphasisTypeBold ">32</strong>, 321-338 (2019).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">6.</div><div class="CitationContent" id="CR6">Barad, K.: Meeting the Universe Halfway: Quantum Physics and the Entanglement of Matter and Meaning en (Duke University Press, 2007).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">7.</div><div class="CitationContent" id="CR7">Benford, S., Bowers, J., Fahlén, L. E., Greenhalgh, C.: Managing mutual awareness in collaborative virtual environments in Proceedings of the conference on Virtual reality software and technology (World Scientific Publishing Co., Inc., USA, 1994), 223-236.</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">8.</div><div class="CitationContent" id="CR8">Best, V., Baumgartner, R., Lavandier, M., Majdak, P., Kop?o, N.: Sound Externalization: A Review of Recent Research. en. Trends in Hearing <strong class="EmphasisTypeBold ">24</strong> (2020).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">9.</div><div class="CitationContent" id="CR9">Bharitkar, S., Kyriakakis, C.: Immersive audio signal processing English (Springer, New York, NY, 2006).<span class="Occurrences"><span class="Occurrence OccurrenceZLBID"><a href="http://www.emis.de/MATH-item?1106.94002"><span><span>zbMATH</span></span></a></span></span></div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">10.</div><div class="CitationContent" id="CR10">Blackwell, A.: Interacting with an inferred world: the challenge of machine learning for humane computer interaction. en (2015).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">11.</div><div class="CitationContent" id="CR11">Boren, B., Geronazzo, M., Brinkmann, F., Choueiri, E.: Coloration metrics for headphone equalization in Proc. of the 21st Int. Conf. on Auditory Display (ICAD 2015) (Graz, Austria, 2015), 29-34.</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">12.</div><div class="CitationContent" id="CR12">Bormann, K.: Presence and the Utility of Audio Spatialization. Presence <strong class="EmphasisTypeBold ">14</strong>, 278-297 (2005).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">13.</div><div class="CitationContent" id="CR13">Bowman, D. et al.: 3D User Interfaces: New Directions and Perspectives. Computer Graphics and Applications, IEEE <strong class="EmphasisTypeBold ">28</strong>, 20-36 (2008).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">14.</div><div class="CitationContent" id="CR14">Bowman, D. A., Hodges, L. F.: Formalizing the Design, Evaluation, and Application of Interaction Techniques for Immersive Virtual Environments. Journal of Visual Languages &amp; Computing <strong class="EmphasisTypeBold ">10</strong>, 37-53 (1999).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">15.</div><div class="CitationContent" id="CR15">Bregman, A. S.: Auditory scene analysis: the perceptual organization of sound (MIT Press, Cambridge, Mass., 1990).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">16.</div><div class="CitationContent" id="CR16">Breves, P., Dodel, N.: The influence of cybersickness and the media devices’ mobility on the persuasive effects of 360<span class="InlineEquation" id="IEq3"><img alt="$$^{\circ }$$" src="../images/478239_1_En_1_Chapter/478239_1_En_1_Chapter_TeX_IEq3.png" style="width:0.57em"/></span> commercials. en. Multimedia Tools and Applications <strong class="EmphasisTypeBold ">80</strong>, 27299-27322 (2021).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">17.</div><div class="CitationContent" id="CR17">Brinkmann, F., Roden, R., Lindau, A., Weinzierl, S.: Audibility and interpolation of head-above-torso orientation in binaural technology. IEEE Journal of Selected Topics in Signal Processing PP, 1-1 (2015).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">18.</div><div class="CitationContent" id="CR18">Brinkmann, F., Lindau, A., Weinzierl, S.: On the authenticity of individual dynamic binaural synthesis. en. The Journal of the Acoustical Society of America <strong class="EmphasisTypeBold ">142</strong>, 1784-1795 (2017).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">19.</div><div class="CitationContent" id="CR19">Broadbent, D. E.: Perception and Communication en (Scientific Book Guild,1958).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">20.</div><div class="CitationContent" id="CR20">Bronkhorst, A. W.: The cocktail-party problem revisited: early processing and selection of multi-talker speech. Attention, Perception &amp; Psychophysics <strong class="EmphasisTypeBold ">77</strong>, 1465-1487 (2015).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">21.</div><div class="CitationContent" id="CR21">Brungart, D. S.: Near-Field Virtual Audio Displays. Presence <strong class="EmphasisTypeBold ">11</strong>, 93-106 (2002).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">22.</div><div class="CitationContent" id="CR22">Brungart, D. S. et al.: The interaction between head-tracker latency, source duration, and response time in the localization of virtual sound sources en. In In Proc. International Conference on Auditory Display 2004 (2004), 7.</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">23.</div><div class="CitationContent" id="CR23">Bruynseels, K., Santoni de Sio, F., van den Hoven, J.: Digital Twins in Health Care: Ethical Implications of an Emerging Engineering Paradigm. Frontiers in Genetics <strong class="EmphasisTypeBold ">9</strong>, 31 (2018).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">24.</div><div class="CitationContent" id="CR24">Bufacchi, R. J., Iannetti, G. D.: An Action Field Theory of Peripersonal Space. Trends in Cognitive Sciences <strong class="EmphasisTypeBold ">22</strong>, 1076-1090 (2018).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">25.</div><div class="CitationContent" id="CR25">Cadet, L. B., Chainay, H.: Memory of virtual experiences: Role of immersion, emotion and sense of presence. en. International Journal of Human-Computer Studies <strong class="EmphasisTypeBold ">144</strong>, 102506 (2020).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">26.</div><div class="CitationContent" id="CR26">Casanueva, J., Blake, E.: en. in Virtual Environments 2000 (eds Hansmann, W., Purgathofer, W., Sillion, F., Mulder, J., van Liere, R.) 85-94 (Springer Vienna, Vienna, 2000).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">27.</div><div class="CitationContent" id="CR27">Catic, J., Santurette, S., Buchholz, J. M., Gran, F., Dau, T.: The effect of interaural-level-difference fluctuations on the externalization of sound. The Journal of the Acoustical Society of America <strong class="EmphasisTypeBold ">134</strong>, 1232-1241 (2013).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">28.</div><div class="CitationContent" id="CR28">in. Advances in Social Theory and Methodology (RLE Social Theory) (eds Cetina, K. K., Cicourel, A. V.) (Routledge, 2014).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">29.</div><div class="CitationContent" id="CR29">Understanding learning in virtual worlds en (eds Childs, M., Peachey, A.) (Springer, London, 2013).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">30.</div><div class="CitationContent" id="CR30">Cho, D. et al.: The dichotomy of presence elements: the where and what in IEEE Virtual Reality, 2003. Proceedings. (2003), 273-274.</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">31.</div><div class="CitationContent" id="CR31">Collins, K. in Essays on Sound and Vision (eds Richardson, J., Hawkins, S.) 263-298 (Helsinki University Press, Helsinki, 2007).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">32.</div><div class="CitationContent" id="CR32">Cooke, D. F., Taylor, C. S. R., Moore, T., Graziano, M. S. A.: Complex movements evoked by microstimulation of the ventral intraparietal area. Proceedings of theNationalAcademy of Sciences of theUnited States of America <strong class="EmphasisTypeBold ">100</strong>, 6163-6168 (2003).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">33.</div><div class="CitationContent" id="CR33">Davis, S., Nesbitt, K., Nalivaiko, E.: A Systematic Review of Cybersickness en. in Proceedings of the 2014 Conference on Interactive Entertainment - IE2014 (ACM Press, Newcastle, NSW, Australia, 2014), 1-9.</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">34.</div><div class="CitationContent" id="CR34">Degli Innocenti, E. et al.: Mobile virtual reality for musical genre learning in primary education. Computers &amp; Education <strong class="EmphasisTypeBold ">139</strong>, 102-117 (2019).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">35.</div><div class="CitationContent" id="CR35">Den Hengst, F., Grua, E. M., el Hassouni, A., Hoogendoorn, M.: Reinforcement learning for personalization: A systematic literature review. en. Data Science <strong class="EmphasisTypeBold ">3</strong>, 107-147 (2020).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">36.</div><div class="CitationContent" id="CR36">DiSalvo, C.: Adversarial Design en (eds Friedman, K., Stolterman, E.) (MIT Press, Cambridge, MA, USA, 2012).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">37.</div><div class="CitationContent" id="CR37">Dörk, M., Comber, R., Dade-Robertson, M.: Monadic exploration: seeing the whole through its parts in Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Association for Computing Machinery, New York, NY, USA, 2014), 1535-1544.</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">38.</div><div class="CitationContent" id="CR38">Dubus, G., Bresin, R.: A Systematic Review of Mapping Strategies for the Sonification of Physical Quantities. PLoS ONE <strong class="EmphasisTypeBold ">8</strong>, e82491 (2013).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">39.</div><div class="CitationContent" id="CR39">Durr, G., Peixoto, L., Souza, M., Tanoue, R., Reiss, J. D.: Implementation and Evaluation of Dynamic Level ofAudio Detail English. in (Audio Engineering Society, 2015).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">40.</div><div class="CitationContent" id="CR40">El Saddik, A.: Digital Twins: The Convergence of Multimedia Technologies. IEEE MultiMedia <strong class="EmphasisTypeBold ">25</strong>, 87-92 (2018).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">41.</div><div class="CitationContent" id="CR41">Ernst, M. O., Bülthoff, H. H.: Merging the senses into a robust percept. Trends in Cognitive Sciences <strong class="EmphasisTypeBold ">8</strong>, 162-169 (2004).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">42.</div><div class="CitationContent" id="CR42">Feasel, J., Whitton, M. C., Wendt, J. D.: LLCM-WIP: Low-latency, continuous-motionwalking-in-place in 3D User Interfaces, 2008. 3DUI 2008. IEEE Symposium on (IEEE, 2008), 97-104.</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">43.</div><div class="CitationContent" id="CR43">Flach, J. M., Holden, J. G.: The Reality of Experience: Gibson’s Way. en. Presence: Teleoperators and Virtual Environments <strong class="EmphasisTypeBold ">7</strong>, 90-95 (1998).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">44.</div><div class="CitationContent" id="CR44">Franinovic, K., Serafin, S.: Sonic Interaction Design en (MIT Press, 2013).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">45.</div><div class="CitationContent" id="CR45">Frauenberger, C.: Entanglement HCI The NextWave? ACM Transactions on Computer-Human Interaction <strong class="EmphasisTypeBold ">27</strong>, 2:1-2:27 (2019).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">46.</div><div class="CitationContent" id="CR46">Friston, K., FitzGerald, T., Rigoli, F., Schwartenbeck, P., Pezzulo, G.: Active Inference: A Process Theory. Neural Computation <strong class="EmphasisTypeBold ">29</strong>, 1-49 (2017).<span class="Occurrences"><span class="Occurrence OccurrenceAMSID"><a href="http://www.ams.org/mathscinet-getitem?mr=3867161"><span><span>MathSciNet</span></span></a></span><span class="Occurrence OccurrenceZLBID"><a href="http://www.emis.de/MATH-item?1414.92092"><span><span>zbMATH</span></span></a></span></span></div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">47.</div><div class="CitationContent" id="CR47">Gallagher, S., Zahavi, D.: The Phenomenological Mind 3rd ed. (Routledge, London, 2020).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">48.</div><div class="CitationContent" id="CR48">Gaver, W. W.: What in the World Do We Hear?: An Ecological Approach to Auditory Event Perception. Ecological Psychology <strong class="EmphasisTypeBold ">5</strong>, 1-29 (1993).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">49.</div><div class="CitationContent" id="CR49">Sonic Interactions in Virtual Environments (eds Geronazzo, M., Serafin, S.) (Springer International Publishing, 2022).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">50.</div><div class="CitationContent" id="CR50">Geronazzo, M., Spagnol, S., Avanzini, F.: Customized 3D Sound for Innovative Interaction Design in Proc. SMC-HCI Work., CHItaly 2011 Conf. (Alghero, Italy, 2011).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">51.</div><div class="CitationContent" id="CR51">Geronazzo, M., Spagnol, S., Avanzini, F.: Do we need individual head-related transfer functions for vertical localization? The case study of a spectral notch distance metric. IEEE/ACM Transactions on Audio, Speech, and Language Processing <strong class="EmphasisTypeBold ">26</strong>, 1243-1256 (2018).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">52.</div><div class="CitationContent" id="CR52">Geronazzo, M., Tissieres, J. Y., Serafin, S.: A Minimal Personalization of Dynamic Binaural Synthesis with Mixed Structural Modeling and Scattering Delay Networks in Proc. IEEE Int. Conf. on Acoust. Speech Signal Process. (ICASSP 2020) (Barcelona, Spain, 2020), 411-415.</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">53.</div><div class="CitationContent" id="CR53">Geronazzo, M., Vieira, L. S., Nilsson, N. C., Udesen, J., Serafin, S.: Superhuman Hearing - Virtual Prototyping of Artificial Hearing: a Case Study on Interactions and Acoustic Beamforming. IEEE Transactions on Visualization and Computer Graphics <strong class="EmphasisTypeBold ">26</strong>, 1912-1922 (2020).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">54.</div><div class="CitationContent" id="CR54">Gibson, E. J., Pick, A. D.: An Ecological Approach to Perceptual Learning and Development en (Oxford University Press, New York, NY, 2000).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">55.</div><div class="CitationContent" id="CR55">Gibson, J. J.: The Ecological Approach to Visual Perception: Classic Edition (Psychology Press, New York, 2014).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">56.</div><div class="CitationContent" id="CR56">Gödde, M., Gabler, F., Siegmund, D., Braun, A.: Cinematic Narration in VR - Rethinking Film Conventions for 360 Degrees en. in Virtual, Augmented and Mixed Reality: Applications in Health, Cultural Heritage, and Industry (eds Chen, J. Y., Fragomeni, G.) (Springer International Publishing, Cham,2018), 184-201.</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">57.</div><div class="CitationContent" id="CR57">Goldstone, R. L.: Perceptual Learning. Annual Review of Psychology <strong class="EmphasisTypeBold ">49</strong>, 585-612 (1998).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">58.</div><div class="CitationContent" id="CR58">Graziano, M. S., Yap, G. S., Gross, C. G.: Coding of visual space by premotor neurons. en. Science <strong class="EmphasisTypeBold ">266</strong>, 1054-1057 (1994).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">59.</div><div class="CitationContent" id="CR59">Graziano, M. S. A., Taylor, C. S. R., Moore, T.: Complex Movements Evoked by Microstimulation of Precentral Cortex. Neuron <strong class="EmphasisTypeBold ">34</strong>, 841-851 (2002).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">60.</div><div class="CitationContent" id="CR60">Grivaz, P., Blanke, O., Serino, A.: Common and distinct brain regions processing multisensory bodily signals for peripersonal space and body ownership. NeuroImage <strong class="EmphasisTypeBold ">147</strong>, 602-618 (2017).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">61.</div><div class="CitationContent" id="CR61">Hachet, M., Decle, F., Knodel, S., Guitton, P.: Navidget for Easy 3D Camera Positioning from 2D Inputs in 2008 IEEE Symposium on 3D User Interfaces (2008), 83-89.</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">62.</div><div class="CitationContent" id="CR62">Hacihabiboglu, H., De Sena, E., Cvetkovic, Z., Johnston, J., Smith III, J. O.:Perceptual SpatialAudioRecording, Simulation, andRendering: An overview of spatial-audio techniques based on psychoacoustics. IEEE Signal Processing Magazine <strong class="EmphasisTypeBold ">34</strong>, 36-54 (2017).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">63.</div><div class="CitationContent" id="CR63">Hall, E. T. et al.: Proxemics [and Comments and Replies]. Current Anthropology <strong class="EmphasisTypeBold ">9</strong>, 83-108 (1968).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">64.</div><div class="CitationContent" id="CR64">Harrison, S., Tatar, D., Sengers, P.: The Three Paradigms of HCI. en, 22 (2007).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">65.</div><div class="CitationContent" id="CR65">Hartmann, W. M., Wittenberg, A.: On the externalization of sound images. The Journal of theAcoustical Society of America <strong class="EmphasisTypeBold ">99</strong>, 3678-3688 (1996).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">66.</div><div class="CitationContent" id="CR66">Hauser, S., Oogjes, D.,Wakkary, R.,Verbeek, P.-P.: AnAnnotated Portfolio on Doing Postphenomenology Through Research Products in Proceedings of the 2018 Designing Interactive Systems Conference (Association for Computing Machinery, New York, NY, USA, 2018), 459-471.</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">67.</div><div class="CitationContent" id="CR67">Heidegger, M.: Being and Time en (Blackwell, 1967).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">68.</div><div class="CitationContent" id="CR68">Hiipakka, M., Kinnari, T., Pulkki, V.: Estimating head-related transfer functions of human subjects from pressure-velocity measurements. The Journal of the Acoustical Society of America <strong class="EmphasisTypeBold ">131</strong>, 4051-4061 (2012).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">69.</div><div class="CitationContent" id="CR69">Holzinger, A.: Interactive machine learning for health informatics: when do we need the human-in-the-loop? en. Brain Informatics <strong class="EmphasisTypeBold ">3</strong>, 119-131 (2016).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">70.</div><div class="CitationContent" id="CR70">Holzinger, A.: From Machine Learning to Explainable AI in 2018 World Symposium on Digital Intelligence for Systems and Machines (DISA) (2018), 55-66.</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">71.</div><div class="CitationContent" id="CR71">Höök, K.: Designing with the Body: Somaesthetic Interaction Design en (MIT Press, 2018).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">72.</div><div class="CitationContent" id="CR72">Höök, K., Löwgren, J.: Strong concepts: Intermediate-level knowledge in interaction design research. ACM Transactions on Computer-Human Interaction <strong class="EmphasisTypeBold ">19</strong>, 23:1-23:18 (2012).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">73.</div><div class="CitationContent" id="CR73">Husserl, E.: Ideas Pertaining to a Pure Phenomenology and to a Phenomenological Philosophy en (Springer Netherlands, 1982).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">74.</div><div class="CitationContent" id="CR74">Ihde, D.: Technology and the Lifeworld: From Garden to Earth Inglese (Indiana Univ Pr, Bloomington, 1990).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">75.</div><div class="CitationContent" id="CR75">Ihlefeld, A., Shinn-Cunningham, B.: Disentangling the effects of spatial cues on selection and formation of auditory objects. J. Acoust. Soc. Am. <strong class="EmphasisTypeBold ">124</strong>, 2224-2235 (2008).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">76.</div><div class="CitationContent" id="CR76">Jerald, J.: The VR Book: Human-Centered Design for Virtual Reality (Association for Computing Machinery and Morgan &amp; Claypool, New York, NY, USA, 2016).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">77.</div><div class="CitationContent" id="CR77">Kanade, T., Rander, P., Narayanan, P. J.: Virtualized reality: constructing virtual worlds from real scenes. IEEE MultiMedia <strong class="EmphasisTypeBold ">4</strong>, 34-47 (1997).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">78.</div><div class="CitationContent" id="CR78">Katz, B. F. G.: Boundary Element Method Calculation of Individual Head- Related Transfer Function. I. Rigid Model Calculation. The Journal of Acoustical Society of America <strong class="EmphasisTypeBold ">110</strong>, 2440-2448 (2001).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">79.</div><div class="CitationContent" id="CR79">Katz, B. F. G.,Weber, A.: An Acoustic Survey of the Cathédrale Notre-Dame de Paris before and after the Fire of 2019. en. Acoustics <strong class="EmphasisTypeBold ">2</strong>, 791-802 (2020).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">80.</div><div class="CitationContent" id="CR80">Kilteni, K., Groten, R., Slater, M.: The Sense of Embodiment in Virtual Reality. Presence <strong class="EmphasisTypeBold ">21</strong>, 373-387 (2012).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">81.</div><div class="CitationContent" id="CR81">Kim, B., Pardo, B.: A Human-in-the-Loop System for Sound Event Detection and Annotation. ACMTransactions on Interactive Intelligent Systems <strong class="EmphasisTypeBold ">8</strong>, 13:1-13:23 (2018).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">82.</div><div class="CitationContent" id="CR82">Laback, B., Majdak, P.: Binaural jitter improves interaural time-difference sensitivity of cochlear implantees at high pulse rates. en. Proceedings of the National Academy of Sciences <strong class="EmphasisTypeBold ">105</strong>, 814-817 (2008).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">83.</div><div class="CitationContent" id="CR83">Larsson, P., Västfjäll, D., Kleiner, M.: Effects of auditory information consistency and room acoustic cues on presence in virtual environments. en. Acoustical Science and Technology <strong class="EmphasisTypeBold ">29</strong>, 191-194 (2008).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">84.</div><div class="CitationContent" id="CR84">Latour, B., Jensen, P., Venturini, T., Grauwin, S., Boullier, D.: ’The whole is always smaller than its parts’ - a digital test of Gabriel Tardes’ monads. en. The British Journal of Sociology <strong class="EmphasisTypeBold ">63</strong>, 590-615 (2012).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">85.</div><div class="CitationContent" id="CR85">Law, J.: Notes on the theory of the actor-network: Ordering, strategy, and heterogeneity. en. Systems practice <strong class="EmphasisTypeBold ">5</strong>, 379-393 (1992).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">86.</div><div class="CitationContent" id="CR86">Lester, M., Boley, J.: The effects of latency on live sound monitoring in Proc. 123 Audio Engin. Soc. Convention (New York, 2007).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">87.</div><div class="CitationContent" id="CR87">Loke, L., Robertson, T.: Moving and making strange: An embodied approach to movement-based interaction design. ACM Transactions on Computer-Human Interaction <strong class="EmphasisTypeBold ">20</strong>, 7:1-7:25 (2013).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">88.</div><div class="CitationContent" id="CR88">Loomis, J. M.: Presence in Virtual Reality and Everyday Life: Immersion within a World of Representation. en. Presence: Teleoperators and Virtual Environments <strong class="EmphasisTypeBold ">25</strong>, 169-174 (2016).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">89.</div><div class="CitationContent" id="CR89">Lupton, D.: The Quantified Self en (John Wiley &amp; Sons, 2016).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">90.</div><div class="CitationContent" id="CR90">Virtual Reality &amp; Augmented Reality in Industry en (eds Ma, D., Gausemeier, J., Fan, X., Grafe, M.) (Springer-Verlag, Berlin Heidelberg, 2011).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">91.</div><div class="CitationContent" id="CR91">Marchionini, G.: Exploratory search: from finding to understanding. Communications of the ACM <strong class="EmphasisTypeBold ">49</strong>, 41-46 (2006).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">92.</div><div class="CitationContent" id="CR92">Mendes, D., Caputo, F. M., Giachetti, A., Ferreira, A., Jorge, J.: A Survey on 3D Virtual Object Manipulation: From the Desktop to Immersive Virtual Environments. en. Computer Graphics Forum <strong class="EmphasisTypeBold ">38</strong>, 21-45 (2019).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">93.</div><div class="CitationContent" id="CR93">Merleau-Ponty, M.: Phenomenology of Perception 1st edition. Inglese (Routledge, Abingdon, Oxon ; New York, 2013).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">94.</div><div class="CitationContent" id="CR94">Metzinger, T. K.: Why Is Virtual Reality Interesting for Philosophers? Frontiers in Robotics and AI <strong class="EmphasisTypeBold ">5</strong>, 101 (2018).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">95.</div><div class="CitationContent" id="CR95">Milgram, P., Kishino, F.: A Taxonomy of Mixed Reality Visual Displays. en. undefined (1994).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">96.</div><div class="CitationContent" id="CR96">M?ynarski, W., McDermott, J. H.: Ecological origins of perceptual grouping principles in the auditory system. en. Proceedings of the National Academy of Sciences (2019).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">97.</div><div class="CitationContent" id="CR97">Moore, P.: Enhancing Me: The Hope and the Hype of Human Enhancement 1st edition. English (Wiley, Chichester, England ; Hoboken, NJ, 2008).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">98.</div><div class="CitationContent" id="CR98">Murray, J. H.: Hamlet on the Holodeck: The Future ofNarrative in Cyberspace Updated Edition. en (MIT Press, Cambridge, MA, USA, 2017).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">99.</div><div class="CitationContent" id="CR99">Nassiri, N., Powell, N., Moore, D.: Human interactions and personal space in collaborative virtual environments. Virtual Reality <strong class="EmphasisTypeBold ">14</strong>, 229-240 (2010).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">100.</div><div class="CitationContent" id="CR100">Nguyen, T.-H.-C., Nebel, J.-C., Florez-Revuelta, F.: Recognition of Activities of Daily Living with Egocentric Vision: A Review. en. Sensors <strong class="EmphasisTypeBold ">16</strong>, 72 (2016).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">101.</div><div class="CitationContent" id="CR101">Nilsson,N. C. et al.: 15Years ofResearch onRedirectedWalking in Immersive Virtual Environments. IEEE Computer Graphics and Applications <strong class="EmphasisTypeBold ">38</strong>, 44-56 (2018).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">102.</div><div class="CitationContent" id="CR102">Nordahl, R., Nilsson, N. C.: The Sound of Being There: Presence and Interactive Audio in Immersive Virtual Reality. en. The Oxford Handbook of Interactive Audio (2014).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">103.</div><div class="CitationContent" id="CR103">Ntoutsi, E. et al.: Bias in data-driven artificial intelligence systems-An introductory survey. en. WIREs Data Mining and Knowledge Discovery <strong class="EmphasisTypeBold ">10</strong>, e1356 (2020).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">104.</div><div class="CitationContent" id="CR104">Nyberg, D.: Computers, Customer Service Operatives and Cyborgs: Intraactions in Call Centres. en. Organization Studies <strong class="EmphasisTypeBold ">30</strong>, 1181-1199 (2009).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">105.</div><div class="CitationContent" id="CR105">Orlikowski, W. J.: The sociomateriality of organisational life: considering technology in management research. Cambridge Journal of Economics <strong class="EmphasisTypeBold ">34</strong>, 125-141 (2010).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">106.</div><div class="CitationContent" id="CR106">Osimo, S. A., Pizarro, R., Spanlang, B., Slater, M.: Conversations between self and self as Sigmund Freud-A virtual body ownership paradigm for self counselling. en. Scientific Reports <strong class="EmphasisTypeBold ">5</strong>, 13899 (2015).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">107.</div><div class="CitationContent" id="CR107">Computational Interaction (eds Oulasvirta, A., Kristensson, P. O., Bi, X., Howes, A.) (Oxford University Press, Oxford, New York, 2018).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">108.</div><div class="CitationContent" id="CR108">Pai, D. K.: Multisensory Interaction: Real and Virtual en. in Robotics Research. The Eleventh International Symposium (eds Dario, P., Chatila, R.) (Springer, Berlin, Heidelberg, 2005), 489-498.</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">109.</div><div class="CitationContent" id="CR109">Parisi, G. I., Kemker, R., Part, J. L., Kanan, C., Wermter, S.: Continual lifelong learning with neural networks: A review. en. Neural Networks <strong class="EmphasisTypeBold ">113</strong>, 54-71 (2019).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">110.</div><div class="CitationContent" id="CR110">Paul, S.: Binaural Recording Technology: A Historical Review and Possible Future Developments. Acta Acustica united with Acustica <strong class="EmphasisTypeBold ">95</strong>, 767-788 (2009).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">111.</div><div class="CitationContent" id="CR111">Pinho, M. S., Bowman, D. A., Freitas, C. M.: Cooperative object manipulation in immersive virtual environments: framework and techniques in Proceedings of the ACM symposium on Virtual reality software and technology (Association for Computing Machinery, New York, NY, USA, 2002), 171-178.</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">112.</div><div class="CitationContent" id="CR112">Polotti, P., Rocchesso, D., Editors, D. R.: Sound to Sense , Sense to Sound A State of the Art in Sound and Music Computing (eds Polotti, P., Rocchesso, D.) (Logos Verlag Berlin, 2008).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">113.</div><div class="CitationContent" id="CR113">Prepelită, S. T., Gómez Bolaños, J., Geronazzo, M., Mehra, R., Savioja, L.: Pinna-related transfer functions and lossless wave equation using finitedifference methods: Verification and asymptotic solution. The Journal of the Acoustical Society of America <strong class="EmphasisTypeBold ">146</strong>, 3629-3645 (2019).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">114.</div><div class="CitationContent" id="CR114">Prepelit,?, S. T., Gómez Bolaños, J., Geronazzo, M., Mehra, R., Savioja, L.: Pinna-related transfer functions and lossless wave equation using finitedifference methods:Validation with measurements. The Journal of theAcoustical Society of America <strong class="EmphasisTypeBold ">147</strong>, 3631-3645 (2020).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">115.</div><div class="CitationContent" id="CR115">Ramstead, M. J., Kirchhoff, M. D., Friston, K. J.: A tale of two densities: active inference is enactive inference. en. Adaptive Behavior <strong class="EmphasisTypeBold ">28</strong>, 225-239 (2020).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">116.</div><div class="CitationContent" id="CR116">Riecke, B. E., Väljamäe, A., Schulte-Pelkum, J.: Moving Sounds Enhance the Visually-induced Self-motion Illusion (Circular Vection) in Virtual Reality. ACM Trans. Appl. Percept. <strong class="EmphasisTypeBold ">6</strong>, 7:1-7:27 (2009).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">117.</div><div class="CitationContent" id="CR117">River, J., MacTavish, T.: Research through provocation: a structured prototyping tool using interaction attributes of time, space and information. The Design Journal <strong class="EmphasisTypeBold ">20</strong>, S3996-S4008 (2017).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">118.</div><div class="CitationContent" id="CR118">Rocchesso, D., Bresin, R., Fernstrom, M.: Sounding objects. IEEE MultiMedia <strong class="EmphasisTypeBold ">10</strong>, 42-52 (2003).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">119.</div><div class="CitationContent" id="CR119">Ronga, I. et al.: Seeming confines: Electrophysiological evidence of peripersonal space remapping following tool-use in humans. en. Cortex (2021).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">120.</div><div class="CitationContent" id="CR120">Rose, T., Nam, C. S., Chen, K. B.: Immersion of virtual reality for rehabilitation - Review. en. Applied Ergonomics <strong class="EmphasisTypeBold ">69</strong>, 153-161 (2018).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">121.</div><div class="CitationContent" id="CR121">Sadeghian, S., Hassenzahl, M.: From Limitations to Superpowers: A Design Approach to Better Focus on the Possibilities of Virtual Reality to Augment Human Capabilities in Designing Interactive Systems Conference 2021 (Association for Computing Machinery, New York, NY, USA, 2021), 180-189.</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">122.</div><div class="CitationContent" id="CR122">Sankaran, N., Hillis, J., Zannoli, M., Mehra, R.: Perceptual thresholds of spatial audio update latency in virtual auditory and audiovisual environments. The Journal of the Acoustical Society of America <strong class="EmphasisTypeBold ">140</strong>, 3008-3008 (2016).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">123.</div><div class="CitationContent" id="CR123">Sapontzis, S. F.: A Note on Merleau-Ponty’s “Ambiguity”. Philosophy and Phenomenological Research <strong class="EmphasisTypeBold ">38</strong>, 538-543 (1978).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">124.</div><div class="CitationContent" id="CR124">Sauzéon, H. et al.: The use of virtual reality for episodic memory assessment: effects of active navigation. eng. Experimental Psychology <strong class="EmphasisTypeBold ">59</strong>, 99-108 (2011).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">125.</div><div class="CitationContent" id="CR125">Schoeffler, M., Herre, J.: About the different types of listeners for rating the overall listening experience in In Proc. of ICMC|SMC|2014 (Athens, 2014), 886-892.</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">126.</div><div class="CitationContent" id="CR126">Schultze, U.: The Avatar as Sociomaterial Entanglement: A Performative Perspective on Identity, Agency and World-Making in Virtual Worlds. ICIS 2011 Proceedings (2011).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">127.</div><div class="CitationContent" id="CR127">Serafin, S., Erkut, C.,Kojs, J., Nilsson,N. C.,Nordahl, R.: VirtualReality Musical Instruments: State of the Art, Design Principles, and Future Directions. Computer Music Journal <strong class="EmphasisTypeBold ">40</strong>, 22-40 (2016).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">128.</div><div class="CitationContent" id="CR128">Serafin, S., Geronazzo, M., Nilsson, N. C., Erkut, C., Nordahl, R.: Sonic interactions in virtual reality: state of the art, current challenges and future directions. IEEE Computer Graphics and Applications <strong class="EmphasisTypeBold ">38</strong>, 31-43 (2018).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">129.</div><div class="CitationContent" id="CR129">Serafin, S. et al.: Reflections from five years of Sonic Interactions in Virtual Environments workshops. Journal of New Music Research <strong class="EmphasisTypeBold ">49</strong>, 24-34 (2020).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">130.</div><div class="CitationContent" id="CR130">Serino, A.: Peripersonal space (PPS) as a multisensory interface between the individual and the environment, defining the space of the self. Neuroscience &amp; Biobehavioral Reviews <strong class="EmphasisTypeBold ">99</strong>, 138-159 (2019).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">131.</div><div class="CitationContent" id="CR131">Shilling, R. D., Shinn-Cunningham, B. in Handbook of virtual environments: Design, implementation, and applications 65-92 (Lawrence Erlbaum Associates Publishers, Mahwah, NJ, US, 2002).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">132.</div><div class="CitationContent" id="CR132">Shinn-Cunningham, B. G., Best, V.: Selective Attention in Normal and Impaired Hearing. Trends in Amplification <strong class="EmphasisTypeBold ">12</strong>, 283-299 (2008).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">133.</div><div class="CitationContent" id="CR133">Skarbez, R., Polys, N. F., Ogle, J. T., North, C., Bowman, D. A.: Immersive Analytics: Theory and Research Agenda. English. Frontiers in Robotics and AI <strong class="EmphasisTypeBold ">6</strong> (2019).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">134.</div><div class="CitationContent" id="CR134">Skarbez, R., Smith, M., Whitton, M. C.: Revisiting Milgram and Kishino’s Reality-Virtuality Continuum. Frontiers in Virtual Reality <strong class="EmphasisTypeBold ">2</strong>, 27 (2021).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">135.</div><div class="CitationContent" id="CR135">Slater, M.: Place illusion and plausibility can lead to realistic behaviour in immersive virtual environments. Philosophical Transactions of the Royal Society B: Biological Sciences <strong class="EmphasisTypeBold ">364</strong>, 3549-3557 (2009).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">136.</div><div class="CitationContent" id="CR136">Slater, M., Brogni, A., Steed, A.: Physiological Responses to Breaks in Presence: A Pilot Study. en. Presence 2003: The 6th annual international workshop on presence <strong class="EmphasisTypeBold ">157</strong>, 4 (2003).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">137.</div><div class="CitationContent" id="CR137">Slater, M., Wilbur, S.: A Framework for Immersive Virtual Environments (FIVE): Speculations on the Role of Presence in Virtual Environments. en. Presence: Teleoperators and Virtual Environments <strong class="EmphasisTypeBold ">6</strong>, 603-616 (1997).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">138.</div><div class="CitationContent" id="CR138">Stevenson, R. A., James, T. W.: Affective auditory stimuli: Characterization of the International Affective Digitized Sounds (IADS) by discrete emotional categories. Behavior Research Methods <strong class="EmphasisTypeBold ">40</strong>, 315-321 (2008).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">139.</div><div class="CitationContent" id="CR139">Stitt, P., Picinali, L., Katz, B. F. G.: Auditory Accommodation to Poorly Matched Non-Individual Spectral Localization Cues Through Active Learning. En. Scientific Reports <strong class="EmphasisTypeBold ">9</strong>, 1063 (2019).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">140.</div><div class="CitationContent" id="CR140">Stockburger, A.: The game environment from an auditory perspective in Proc. Level Up: Digital Games Research Conference (eds Copier, M., Raessens, J.) (Utrecht, 2003).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">141.</div><div class="CitationContent" id="CR141">Suchman, L.: Human/Machine Reconsidered. Cognitive Studies: Bulletin of the Japanese Cognitive Science Society <strong class="EmphasisTypeBold ">5</strong>, 1\_5-1\_13 (1998).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">142.</div><div class="CitationContent" id="CR142">Sugimoto, M., Hosoi, K., Hashizume, H.: Caretta: a system for supporting face-to-face collaboration by integrating personal and shared spaces in Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Association for Computing Machinery, New York, NY, USA, 2004), 41-48.</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">143.</div><div class="CitationContent" id="CR143">Tarde, G.: Monadology and Sociology Illustrated edition. English. Trans. By Lorenc, T. (re.press, 2012).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">144.</div><div class="CitationContent" id="CR144">Teneggi, C., Canzoneri, E., di Pellegrino, G., Serino, A.: Social Modulation of Peripersonal Space Boundaries. Current Biology <strong class="EmphasisTypeBold ">23</strong>, 406-411 (2013).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">145.</div><div class="CitationContent" id="CR145">Tsingos, N., Gallo, E., Drettakis, G.: Perceptual audio rendering of complex virtual environments. ACM Transactions on Graphics <strong class="EmphasisTypeBold ">23</strong>, 249-258 (2004).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">146.</div><div class="CitationContent" id="CR146">Udesen, J., Piechowiak, T., Gran, F.: The Effect of Vision on Psychoacoustic Testing with Headphone-Based Virtual Sound. Journal of the Audio Engineering Society <strong class="EmphasisTypeBold ">63</strong>, 552-561 (2015).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">147.</div><div class="CitationContent" id="CR147">Välimäki, V., Parker, J. D., Savioja, L., Smith, J. O., Abel, J. S.: Fifty Years of Artificial Reverberation. IEEE Transactions on Audio, Speech, and Language Processing <strong class="EmphasisTypeBold ">20</strong>, 1421-1448 (2012).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">148.</div><div class="CitationContent" id="CR148">Varela, F., Thompson, E., Rosch, E.: The Embodied Mind (MIT Press, Cambridge, MA, 1991).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">149.</div><div class="CitationContent" id="CR149">Verbeek, P.-P.: Cyborg intentionality: Rethinking the phenomenology of human-technology relations. Phenomenology and the Cognitive Sciences <strong class="EmphasisTypeBold ">7</strong>, 387-395 (2008).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">150.</div><div class="CitationContent" id="CR150">Verbeek, P.-P.: Beyond interaction: a short introduction to mediation theory. Interactions <strong class="EmphasisTypeBold ">22</strong>, 26-31 (2015).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">151.</div><div class="CitationContent" id="CR151">Vindenes, J., Wasson, B.: A Postphenomenological Framework for Studying User Experience of Immersive Virtual Reality. Frontiers in Virtual Reality <strong class="EmphasisTypeBold ">2</strong>, 40 (2021).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">152.</div><div class="CitationContent" id="CR152">Von Berg, M., Steffens, J., Weinzierl, S., Müllensiefen, D.: Assessing room acoustic listening expertise. The Journal of the Acoustical Society of America <strong class="EmphasisTypeBold ">150</strong>, 2539-2548 (2021).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">153.</div><div class="CitationContent" id="CR153">Vorländer, M.: Virtual Acoustics. Archives of Acoustics <strong class="EmphasisTypeBold ">39</strong> (2015).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">154.</div><div class="CitationContent" id="CR154">Warren,W. H.: Direct Perception: The View from Here. Philosophical Topics <strong class="EmphasisTypeBold ">33</strong>, 335-361 (2005).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">155.</div><div class="CitationContent" id="CR155">Weibel, D.,Wissmath, B., Mast, F.W.: Immersion in mediated environments: the role of personality traits. eng. Cyberpsychology, Behavior and Social Networking <strong class="EmphasisTypeBold ">13</strong>, 251-256 (2010).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">156.</div><div class="CitationContent" id="CR156">Witmer, B. G., Singer, M. J.: Measuring Presence in Virtual Environments: A Presence Questionnaire. Presence: Teleoperators and Virtual Environments <strong class="EmphasisTypeBold ">7</strong>, 225-240 (1998).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">157.</div><div class="CitationContent" id="CR157">Xiangyu Wang, P. S. D.: A user-centered taxonomy for specifying mixed reality systems for aec industry. ITcon Vol. <strong class="EmphasisTypeBold ">16</strong>, 493-508 (2011).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">158.</div><div class="CitationContent" id="CR158">Zacharov, N.: Sensory Evaluation of Sound en (CRC Press, 2019).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">159.</div><div class="CitationContent" id="CR159">Zahorik, P., Jenison, R. L.: Presence as Being-in-the-World. Presence: Teleoperators and Virtual Environments <strong class="EmphasisTypeBold ">7</strong>, 78-89 (1998).</div></li><li class="Citation" epub:type="biblioentry" role="doc-biblioentry"><div class="CitationNumber">160.</div><div class="CitationContent" id="CR160">Zonooz, B., Opstal, A. J.V.: DifferentialAdaptation in Azimuth and Elevation to Acute Monaural Spatial Hearing after Training with Visual Feedback. en. eNeuro <strong class="EmphasisTypeBold ">6</strong> (2019).</div></li></ol></div></aside><aside aria-label="Footnotes" class="FootnoteSection" epub:type="footnotes"><div class="Heading">Footnotes</div><div class="Footnote"><span class="FootnoteNumber"><a href="#Fn1_source">1</a></span><div class="FootnoteContent" epub:type="footnote" id="Fn1" role="doc-footnote"><p class="Para" id="Par9">For a dedicated discussion on the basic notions related to presence, please refer also to Chap. <span class="ExternalRef"><a href="478239_1_En_11_Chapter.xhtml"><span class="RefSource">11</span></a></span> in this volume.</p></div><div class="ClearBoth"> </div></div><div class="Footnote"><span class="FootnoteNumber"><a href="#Fn2_source">2</a></span><div class="FootnoteContent" epub:type="footnote" id="Fn2" role="doc-footnote"><p class="Para" id="Par22"><span class="ExternalRef"><a href="https://smcnetwork.org/"><span class="RefSource">https://​smcnetwork.​org/​</span></a></span></p></div><div class="ClearBoth"> </div></div><div class="Footnote"><span class="FootnoteNumber"><a href="#Fn3_source">3</a></span><div class="FootnoteContent" epub:type="footnote" id="Fn3" role="doc-footnote"><p class="Para" id="Par24"><span class="ExternalRef"><a href="https://icad.org/"><span class="RefSource">https://​icad.​org/​</span></a></span></p></div><div class="ClearBoth"> </div></div><div class="Footnote"><span class="FootnoteNumber"><a href="#Fn4_source">4</a></span><div class="FootnoteContent" epub:type="footnote" id="Fn4" role="doc-footnote"><p class="Para" id="Par26"><span class="ExternalRef"><a href="https://www.aes.org/"><span class="RefSource">https://​www.​aes.​org/​</span></a></span></p></div><div class="ClearBoth"> </div></div><div class="Footnote"><span class="FootnoteNumber"><a href="#Fn5_source">5</a></span><div class="FootnoteContent" epub:type="footnote" id="Fn5" role="doc-footnote"><p class="Para" id="Par28"><span class="ExternalRef"><a href="https://nime.org"><span class="RefSource">https://​nime.​org</span></a></span></p></div><div class="ClearBoth"> </div></div><div class="Footnote"><span class="FootnoteNumber"><a href="#Fn6_source">6</a></span><div class="FootnoteContent" epub:type="footnote" id="Fn6" role="doc-footnote"><p class="Para" id="Par30"><span class="ExternalRef"><a href="https://www.dafx.de/"><span class="RefSource">https://​www.​dafx.​de/​</span></a></span></p></div><div class="ClearBoth"> </div></div><div class="Footnote"><span class="FootnoteNumber"><a href="#Fn7_source">7</a></span><div class="FootnoteContent" epub:type="footnote" id="Fn7" role="doc-footnote"><p class="Para" id="Par63"><span class="ExternalRef"><a href="http://getnarrative.com/"><span class="RefSource">http://​getnarrative.​com/​</span></a></span></p></div><div class="ClearBoth"> </div></div><div class="Footnote"><span class="FootnoteNumber"><a href="#Fn8_source">8</a></span><div class="FootnoteContent" epub:type="footnote" id="Fn8" role="doc-footnote"><p class="Para" id="Par64"><span class="ExternalRef"><a href="https://gopro.com/"><span class="RefSource">https://​gopro.​com/​</span></a></span></p></div><div class="ClearBoth"> </div></div><div class="Footnote"><span class="FootnoteNumber"><a href="#Fn9_source">9</a></span><div class="FootnoteContent" epub:type="footnote" id="Fn9" role="doc-footnote"><p class="Para" id="Par68">Atherton and Wang [<span class="CitationRef"><a epub:type="biblioref" href="#CR4" role="doc-biblioref">4</a></span>] recently developed a similar view point comparison and proposed a set of design principles for VR, born from the contrast between “doing vs, being”.</p></div><div class="ClearBoth"> </div></div><div class="Footnote"><span class="FootnoteNumber"><a href="#Fn10_source">10</a></span><div class="FootnoteContent" epub:type="footnote" id="Fn10" role="doc-footnote"><p class="Para" id="Par71">The HRTF selection process can potentially result from a random choice [<span class="CitationRef"><a epub:type="biblioref" href="#CR139" role="doc-biblioref">139</a></span>].</p></div><div class="ClearBoth"> </div></div></aside></div></div></body></html>